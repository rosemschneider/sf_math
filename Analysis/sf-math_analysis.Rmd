---
title: "SF-Math analysis"
author: "Rose Schneider"
date: "5/13/2018"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
rm(list = ls())
require("knitr")
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

---

#Setup
##Loading data
Raw data is read in and processed in sf-math_dataProc.R, which is called here. Processed data are then read in
```{r}
source_r <- function(file, local = FALSE, ...){
  options(knitr.duplicate.label = 'allow')

  tempR <- tempfile(tmpdir = ".", fileext = ".R")
  on.exit(unlink(tempR))
  knitr::purl(file, output=tempR, quiet = TRUE)

  envir <- globalenv()
  source(tempR, local = envir, ...)
}

source_r("sf-math_dataProc.R")
#this results in a cleaned .csv, re-compiled every time from original data
```

##Read in processed data
```{r}
all.data <- read.csv("../Data/sf-math_data_processed.csv")
```
---

#Exclusions 
##Global exclusions
Children were excluded from the analysis only if a) they did not complete the highest count task or Give N, or b) their exclusion was noted by the experimenter. 

Pre-exclusion kids
```{r}
##How many kids pre-exclusions?
all.data %>%
  distinct(SID)%>%
  summarise(n = n())%>%
  kable()
```

Exclusion reasons
```{r}
#Why are kids being excluded?
all.data %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis, Exclude_analysis_reason)%>%
  group_by(Exclude_analysis_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n)) %>%
  kable()
```

```{r}
#exclude these kids from analysis
all.data %<>%
  filter(Exclude_analysis != 1)
```

How many kids left after exclusions?
```{r}
#How many kids are left after exclusions
all.data %>%
  distinct(SID)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))%>%
  kable()
```

Sex
```{r}
all.data %>%
  distinct(SID, Sex)%>%
  group_by(Sex)%>%
  summarise(n = n())
```

###Task exclusions
Children were excluded from a given task if they did not complete at least ONE trials of that task (in addition to the training trial). In order to be considered as having completed a trial of the task, a child must at least say "I don't know."  These children were excluded manually.
```{r}
#how many kids are excluded from which tasks
all.data %>%
  filter(Exclude_task == 1)%>%
  distinct(SID, Exclude_task, Excluded_task, Exclude_task_reason)%>%
  kable()

#exclude
all.data %<>%
  filter(Exclude_task != 1)
```

##Excluded trials
Trials where a participant gave no response were excluded from analysis.

How many trials were excluded? Why?
```{r}
#how many trials excluded, and for what reason
all.data %>%
  filter(Exclude_trial == 1)%>%
  group_by(Task, Exclude_trial_reason)%>%
  summarise(n = n())%>%
  kable()

#exclude these trials
all.data %<>%
  filter(Exclude_trial != 1)
```

How many kids failed training? In what task?
```{r}
#how many kids failed training
all.data %>%
  filter(Trial_number == "Training", #note that only one kid failed first trial of SF, no kid failed all
         Correct == 0)%>%
  group_by(Task)%>%
  summarise(n = n()) %>%
  kable()

#filter out training trials 
all.data %<>%
  filter(Trial_number != "Training")

#how many trials do we have for each task?
all.data %>%
  filter(Task == "SF" | 
         Task == "WCN" |
           Task == "MF")%>%
  group_by(Task)%>%
  summarise(n = n()) %>%
  kable()
```

---
#More classifications (post exclusion)

##Within/outside count range
Each trial on the Unit or WCN task was determined to be either within or outside a child's unprompted count range (IHC).
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "WCN" | Task == "MF") & 
                                as.numeric(as.character(Task_item)) <= IHC, "Within", 
                              ifelse((Task == "SF" | Task == "WCN" | Task == "MF") &
                                       as.numeric(as.character(Task_item)) > IHC, "Outside", NA))) %>%
  mutate(count_range = factor(count_range, levels = c("Within", "Outside")))
```

##Mean performance for Indefinite, Unit, NN, and MF
Mean performance on the indefinite number task for children who received it.
```{r}
indef.mean <- all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID)%>%
  summarise(mean.indef = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, indef.mean, by = "SID")

mf.sum <- all.data %>%
  filter(Task == "MF")%>%
  group_by(SID)%>%
  summarise(mean.mf = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, mf.sum, by = "SID")

sf.mean <- all.data %>%
  filter(Task == "SF")%>%
  group_by(SID)%>%
  summarise(mean.unit = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, sf.mean, by = "SID")

nn.mean <- all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID)%>%
  summarise(mean.nn = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, nn.mean, by = "SID")
```

---
##Demographics
```{r}
all.data %>%
  distinct(SID, Age)%>%
  summarise(mean = round(mean(Age), 2), 
            sd = round(sd(Age), 2))%>%
  kable()

#sex
all.data %>%
  distinct(SID, Sex)%>%
  group_by(Sex)%>%
  summarise(n = n())%>%
  kable()
```

---

#Primary analyses
17.1 Counting Productivity &amp; Successor Task Performance: To identify whether there is connection between counting experience and Successor Task performance, we will conduct three initial analyses, predicting Successor Task performance from either (1) Initial Highest Count, (2) Productivity (defined above), (3) final highest count, or (4) performance on the Next Number task.

All models will be logistic mixed effects models, predicting performance on a trial as a function of the following
predictors, with a random intercept for subject. In R, the formula will be glmer(SF_correct ~ (predictor) + age + (1|subject), family = binomial).
Simple Models
-  Model 1: Successor.Performance ~ Highest.Next.Number + Within/Outside range + Age + (1|subject)
-  Model 2: Successor.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Successor.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 4: Successor.Performance ~ Productivity+ Within/Outside range + Age + (1|subject)

After running these first four models, any predictor that significantly (p &lt;.05) predicted Successor Performance will be added into Model 5, which will be our “Large” model (containing all predictors that significantly predicted Successor Performance in the simple models).

We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

First, make the model df
```{r}
model.df <- all.data %>%
  mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         mean.indef.c = as.vector(scale(mean.indef, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(Task == "SF")
```

Make the models 
```{r}
#base
sf.base <- glmer(Correct ~ count_range  + age.c + (1|SID), 
                 family = "binomial", data = model.df)
# #highest nn
# sf.highest_nn <- glmer(Correct ~ highest_num.c + count_range + age.c + (1|SID), 
#                  family = "binomial", data = model.df)

#ihc
sf.ihc <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#fhc
sf.fhc <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Productive
sf.prod <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Highest contiguous NN
sf.highest_contig <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

# #Productivity gradient
# sf.prod.gradient <- glmer(Correct ~ prod.gradient + count_range + age.c + (1|SID), 
#                  family = "binomial", data = model.df)
```

##Regression table
```{r}
library(memisc)
mtable.sf <- mtable('Base Model' = sf.base,
            # 'Model 1: Highest NN' = sf.highest_nn,
            'Model 2: IHC' = sf.ihc,
            'Model 3: FHC' = sf.fhc,
            'Model 4: Productivity.' = sf.prod,
            'Model 5: HCNN' = sf.highest_contig,
            # 'Model 6: Prod. gradient' = sf.prod.gradient,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf

```

###Test of productivity predictor in comparison to base
```{r}
# #base v. highest nn
# anova(sf.base, sf.highest_nn, test = 'LRT')
#base v. ihc
anova(sf.base, sf.ihc, test = 'LRT')
#base v. fhc
anova(sf.base, sf.fhc, test = 'LRT')
#base v. productive
anova(sf.base, sf.prod, test = 'LRT')
#base v. highest_contig
anova(sf.base, sf.highest_contig, test = 'LRT')
# #base. v. prod. gradient
# anova(sf.base, sf.prod.gradient, test = 'LRT')
```

##Ordering of productivity predictor by AIC: 
HCNN: 2650.2
FHC: 2688.5
IHC: 2701.3
Productive: 2738.5


##Model comparisons: Large model (with HCNN)
Start with HCNN, strongest predictor.
```{r}
#HCNN
sf.large.base <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)

#HCNN + FHC
sf.large.plusfhc <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.base, sf.large.plusfhc, test = 'LRT') #FHC adds to this model

#IHC + FHC 
sf.large.plusihc <- glmer(Correct ~ ihc.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.plusfhc, sf.large.plusihc, test = 'LRT') #IHC does not add to this model

##Productivity + FHC
sf.large.plusprod <- glmer(Correct ~ Productive + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.plusfhc, sf.large.plusprod, test = 'LRT') #productivity does not add to this model 

##model table
mtable.sf.large <- mtable('Base Model: HCNN' = sf.large.base,
            'Model 1: FHC + HCNN' = sf.large.plusfhc,
            'Model 2: IHC + FHC + HCNN' = sf.large.plusihc,
            'Model 3: Prod. + FHC + HCNN' = sf.large.plusprod,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.large
```

#Math Facts model 
Is mean Math Facts performance significantly predictive of SF knowledge? Yes - Chisq(1) = 54.66, p < .0001
```{r}
#build model
sf.mf <- glmer(Correct ~ mean.mf.c + count_range + age.c + (1|SID), 
               family = "binomial", data = model.df)

#test
anova(sf.base, sf.mf, test = 'LRT')
mtable('Math Facts' = sf.mf)
```

##Model comparison, Math Facts + FHC + HCNN
Does Math Facts explain unique variance on top of FHC? 
Yes - added to a model with FHC & HCNN, mean math facts performance explains unique variance. 
```{r}
sf.large.plusmf <- glmer(Correct ~ mean.mf.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.plusfhc, sf.large.plusmf) #math facts significantly adds to the model

summary(sf.large.plusmf)
library(sjPlot)
tab_model(sf.large.plusmf, transform = NULL)
```

***

#Testing whether SF is generalized from Math Facts
If children are acquiring SF from MF, we should expect that all children who demonstrate mastery of SF (in top quartile), should similarly be at ceiling (or close to ceiling, >.75 mean performance) in MF. 

```{r}
#add quartiles for unit task
all.data %<>%
  mutate(sf.quartile = cut(mean.unit, 
                                breaks=quantile(mean.unit, na.rm=TRUE), 
                                include.lowest=TRUE))

##ANALYSIS
#Looking only at children who are at ceiling in the Unit Task, are they also at ceiling in the MF task?
model.mf.sf.ceiling.df <- all.data %>%
  filter(Task == "SF" | 
           Task == "WCN" |
           Task == "MF", 
         sf.quartile == "(0.875,1]")%>%
   mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         mean.indef.c = as.vector(scale(mean.indef, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  mutate(Task = factor(Task, levels = c("SF", "MF", "WCN")))

#make base model
mf.sf.ceiling.base <- glmer(Correct ~ count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.ceiling.df)
#now add task
mf.sf.ceiling.task <- glmer(Correct ~ Task + count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.ceiling.df)
#test to see if there is a difference by task 
anova(mf.sf.ceiling.base, mf.sf.ceiling.task, test = 'LRT') #yes, there is a significant effect of task

#summary
summary(mf.sf.ceiling.task)
```

###Follow up on the ceiling unit task analysis with an analysis which has all children
```{r}
model.mf.sf.all.df <- all.data %>%
  filter(Task == "SF" | 
           Task == "WCN" |
           Task == "MF")%>%
   mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         mean.indef.c = as.vector(scale(mean.indef, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  mutate(Task = factor(Task, levels = c("SF", "MF", "WCN")))

#make base model
mf.sf.all.base <- glmer(Correct ~ count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.all.df)
#now add task
mf.sf.all.task <- glmer(Correct ~ Task + count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.all.df)
#test to see if there is a difference by task 
anova(mf.sf.all.base, mf.sf.all.task, test = 'LRT') #yes, there is a significant effect of task

#summary
summary(mf.sf.all.task)

```

## Bar graph showing difference between MF and NN as function of SF
```{r}
three.pal <- c("#173BAB", "#5CA7D8", "#DE8141")

all.data %>%
  filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF")%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit Task", "Next Number", "Math Facts")), 
        sf.quartile = factor(sf.quartile, labels = c("25% — 44%", "44% — 63%", "63% — 88%", "88% — 100%")))%>%
  group_by(SID, Task, sf.quartile)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Task, y = mean, fill=Task)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  # geom_violin(alpha = .5) +
  geom_point(aes(x = Task, y = mean, colour = Task),
               position=position_jitter(width = .18, height = .035),
               size=1.5,
               show.legend=FALSE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, size = 1)+
  ylab("Mean task performance") + 
  xlab('Unit Task performance quartiles') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        legend.position = "top") +
  ylim(0, 1.0) +
  scale_fill_manual(values = three.pal) +
  scale_colour_manual(values = three.pal, guide = "none") + 
  facet_wrap(~sf.quartile, strip.position = "bottom", ncol = 4)

ggsave("~/Documents/Projects/sf_math/Analysis/all_tasks.png", width = 7, height = 4)
```

---

#Highest Count

Descriptives
```{r}
#rename productivity
all.data %<>%
  mutate(Productive = factor(Productive, levels = c("Productive", "Nonproductive"), 
                             labels = c("Resilient", "Non-Resilient")))

productivity.pal <- c("#00b8e6", "#666666")

all.data %>%
  distinct(SID, Age, Productive, IHC, FHC)%>%
  group_by(Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC)), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC)), 
            mean_FHC = round(mean(FHC)), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC)))%>%
  kable()

#overall IHC and FHC
all.data %>%
  distinct(SID, Age, Productive, IHC, FHC)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC)), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC)), 
            mean_FHC = round(mean(FHC)), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC)))%>%
  kable()
```

##Scatterplot/density of IHC/FHC
```{r}
initial_final <- all.data %>%
  filter(!is.na(Productive))%>%
  distinct(SID, IHC, FHC, Productive)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

library(ggstance)
library(ggjoy)
library(cowplot)
####Cantonese####
pmain <- ggplot(initial_final, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 3, alpha = .8, position = position_jitter()) + 
  # geom_jitter() + 
  scale_color_manual(values = productivity.pal) + 
  coord_fixed() + 
  theme_bw(base_size = 15) +
  scale_x_continuous(breaks = seq(0, 120, 10)) + 
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.title = element_text(size = 12),
        legend.position = c(.75, 0.2), 
        legend.text = element_text(size = 10), 
        legend.title = element_blank(), 
        axis.text = element_text(size = 11)) + 
  labs(x = "Initial Highest Count", y = "Final Highest Count") 

xdens <- axis_canvas(pmain, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = initial_final, aes(x = IHC, y = ..density.., fill = Productive), 
               alpha=.4, adjust = .5) + 
  scale_fill_manual(values = productivity.pal) 

ydens <- axis_canvas(pmain, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = initial_final, aes(x = FHC, y = ..density.., fill = Productive), 
               alpha=.4, adjust = .5) +
  coord_flip() +
  scale_fill_manual(values = productivity.pal) 

p5 <- insert_xaxis_grob(pmain, xdens, grid::unit(.2, "null"), position = "top")
count_dens <- insert_yaxis_grob(p5, ydens, grid::unit(.2, "null"), position = "right")
ggdraw(count_dens)
ggsave("~/Documents/Projects/sf_math/Analysis/density.png")
# ggdraw(p6)
# png(filename = "hk_density.png")
# ggdraw(p6)
# dev.off()
```

###How many children who stopped before 120 were able to count at least a little beyond their IHC?
```{r}
#how many kids counted spontaneously to 120?
all.data %>%
  distinct(SID, IHC)%>%
  filter(IHC == 120)

error.freq %>%
  distinct(SID, IHC, FHC)%>%
  filter(IHC != 120)%>%
  mutate(delta.count = FHC-IHC, 
         counted.beyond = ifelse(delta.count > 0, "counted beyond IHC", "could not count beyond IHC"))%>%
  group_by(counted.beyond)%>%
  summarise(n = n(), 
            mean.delta = mean(delta.count))
```


Prompts by productivity
```{r}
#how many prompts do productive and nonproductive counters need? and what kind of errors do they make?
#bind productive and hc.df 
productive %<>% 
  dplyr::select(SID, Productive)

error.freq <- full_join(hc.df, productive, by = "SID")%>%
  filter(!is.na(Last_successful))%>%
  mutate(Error_type = ifelse(Last_successful %% 10 == 9 , "Decade end", 
                             ifelse(Last_successful %% 10 == 0, "Decade beginning", "Mid-decade")))

#mean number of prompts by Productivity
mean_prompts.type <- error.freq %>%
  group_by(Productive, Error_type)%>%
  summarise(n = n())%>%
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)
mean_prompts.type %>%
  kable()

```

##Where are errors happening?
```{r}
error.freq.decade <- error.freq %>%
  mutate(error.decade = ifelse(Last_successful < 10, 0, 
                               ifelse(Last_successful >= 10 & Last_successful < 20, 10, 
                                      ifelse(Last_successful >= 20 & Last_successful < 30, 20, 
                                             ifelse(Last_successful >= 30 & Last_successful < 40, 30, 
                                                    ifelse(Last_successful >=40 & Last_successful < 50, 40, 
                                                           ifelse(Last_successful >= 50 & Last_successful < 60, 50, 
                                                                  ifelse(Last_successful >= 60 & Last_successful < 70, 60, 
                                                                         ifelse(Last_successful >= 70 & Last_successful < 80, 70, 
                                                                                ifelse(Last_successful >= 80 & Last_successful < 90, 80, 
                                                                                       ifelse(Last_successful >= 90 & Last_successful < 100, 90, 
                                                                                              ifelse(Last_successful >= 100 & Last_successful < 110, 100, 110)))))))))))) %>%
  mutate(error.base = (error.decade - Last_successful) * -1, 
         error.base = ifelse(Last_successful == 120, 0, as.numeric(error.base)))
```


###Error by decade
```{r}
error.freq.decade %>%
  mutate(error.decade = factor(error.decade, levels = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 
                                                        90, 100, 110)),
         error.base = factor(error.base))%>%
  group_by(Productive, error.decade)%>%
  summarise(n = n())%>% 
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.decade, y = Productive)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 2.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 10) + 
  labs(x = "Decade of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())
```

###Error by unit
```{r}
error.freq.decade %>%
  filter(Last_successful <= 120)%>% #filter out trials where kid kept going beyond 140
  mutate(error.base = factor(error.base))%>%
  group_by(Productive, error.base)%>%
  summarise(n = n())%>% 
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.base, y = Productive)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 2.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 10) + 
  labs(x = "Unit of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())
```



##How many errors?
```{r}
error.freq %>%
  filter(Last_successful != 120)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  group_by()%>%
  summarise(mean_prompts = round(mean(n, na.rm = TRUE), 2),
            sd_prompts = round(sd(n, na.rm = TRUE), 2), 
            median_prompts = round(median(n, na.rm = TRUE), 2),
            max_prompt = max(n, na.rm = TRUE), 
            min_prompt = min(n, na.rm = TRUE))%>%
  kable()
```

---

#Figure: NN accuracy by HNN and HCNN
```{r}
#get mean performance for highest NN
ms.hnn <- all.data %>%
  filter(Task == "WCN")%>%
  mutate(Number = factor(highest_num, levels = c("0", "7", 
                                                            "24", "26", "30", 
                                                            "62", "71", "83", "95")))%>%
  group_by(Number)%>%
  summarise(n = n(), 
            mean = mean(Correct, na.rm = TRUE), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n))%>%
  mutate(Type = "Highest Next Number")

#get mean performance for HCNN
ms.hcnn <- all.data %>%
  filter(Task == "WCN")%>%
  mutate(Number = factor(highest_contig, levels = c("0", "1", "7", 
                                                            "24", "26", "30", 
                                                            "62", "71", "83", "95")))%>%
  group_by(Number)%>%
  summarise(n = n(), 
            mean = mean(Correct, na.rm = TRUE), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n))%>%
  mutate(Type = "Highest Contiguous Next Number")

#bind_rows
ms.highest.all <- bind_rows(ms.hnn, ms.hcnn)

#combine, plot
ms.highest.all %>%
  mutate(Number = factor(Number, levels = c("0", "1", "7", 
                                                            "24", "26", "30", 
                                                            "62", "71", "83", "95")))%>%
  ggplot(aes(x = Number, y = mean, color = Type, group = Type)) + 
  geom_point(size = 2) + 
  geom_line(linetype = "dashed") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) + 
  theme_bw(base_size = 13) + 
  theme(panel.grid = element_blank(), 
        legend.title = element_blank(), 
        legend.position = "top") + 
  labs(x = "Number reached", y = "Mean Next Number performance") +
  scale_color_brewer(palette = "Paired")

 ggsave("~/Documents/Projects/sf_math/Analysis/nn_by_hcnn.png", width = 5.5, height = 4.5)

```

---

#Performance by Resilience: Unit, NN, Math Facts
##Descriptives
```{r}
all.data %>%
  filter(Task == "SF" | 
           Task == "WCN" | 
           Task == "MF")%>%
  group_by(Task, Productive)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            sd = sd(Correct, na.rm = TRUE))%>%
  kable()
```

##Figure: Mean performance by Resilience
```{r}
all.data %>%
  filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF")%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit Task", "Next Number", "Math Facts")))%>%
  group_by(SID, Productive, Task)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  # geom_violin(alpha = .5) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width = .18, height = .035),
               size=1.5,
               show.legend=FALSE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, size = 1)+
  ylab("Mean task performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        legend.position = "right", 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) +
  scale_colour_manual(values = productivity.pal, guide = "none") + 
  facet_grid(~Task)
# 
ggsave("~/Documents/Projects/sf_math/Analysis/mean_resilience.png", width = 7, height = 3.5)
```

##Analysis: Do Resilient Counters have better performance on tasks?
```{r}
#make model with mean performance
ms.task <- all.data %>%
  distinct(SID, Productive, Age, mean.unit, mean.mf, mean.nn)%>%
  gather(key = "Task", value = "mean", -SID, - Productive, -Age)%>%
  mutate(Task = ifelse(Task == "mean.unit", "SF", 
                       ifelse(Task == "mean.nn", "WCN", "MF")))%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF")))%>%
  mutate(Productive = factor(Productive, levels = c("Non-Resilient", "Resilient")))

#mean performance
resil.lm <- lm(mean ~ Productive + Task + Age, 
               data = ms.task)

#summary
summary(resil.lm)

#re-order
summary(lm(mean ~ Productive + relevel(Task, ref = "WCN") + Age, 
               data = ms.task))
```

---

#Performance within/outside count range
Do Resilient counters do better for numbers outside their Initial Highest Count?
```{r}
#need to get only kids that have numbers which fall outside their count range
#filters out n = 28 kids
model.mf.sf.all.df %<>%
  mutate(Prod.tertiary = ifelse(IHC >= 95, "Resilient IHC >= 95", 
                                ifelse((IHC < 95 & Productive == "Resilient"), "Resilient IHC < 95", "Non-Resilient")))

model.mf.sf.all.df %>%
  group_by(SID, Prod.tertiary, count_range, Task)%>%
  summarise(n = n(), 
            mean = mean(Correct, na.rm = TRUE), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/(sqrt(n)))%>%
  ggplot(aes(x = count_range, y = mean, fill = Prod.tertiary)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  # geom_violin(alpha = .5) +
  # geom_point(aes(x = count_range, y = mean, colour = Prod.tertiary),
  #              position=position_jitter(width = .18, height = .035),
  #              size=1.5,
  #              show.legend=FALSE, 
  #            inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, size = 1)+
  ylab("Mean task performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        legend.position = "right", 
        legend.title = element_blank()) +
  ylim(0, 1.0) + 
  facet_grid(~Task)

#look at only participants who have items within/outside their IHC
range.base <- glmer(Correct ~ count_range*Productive + Task + age.c + (1|SID),
                    family = "binomial", data = subset(model.mf.sf.all.df, IHC < 95))

summary(range.base)#no significant interaction between count range and Productivity
```

---

#Exploratory: Indefinite Next Number 
Descriptives by item
```{r}
all.data %>%
  filter(Task == "Indefinite", 
         !is.na(Correct))%>%
  group_by(Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            sd = sd(Correct, na.rm = TRUE))%>%
  kable()
```

Note: This does not include all participants
```{r}
#filter out anyone who has NA for mean indef
indef.model <- model.df %>%
  filter(!is.na(mean.indef.c))

#does mean indefinite next number performance predict Unit Task
#is indefinite on its own predictive
indef.base.single <- glmer(Correct ~ count_range + age.c + (1|SID), 
                    family = "binomial", data = indef.model)
indef.indef.single <- glmer(Correct ~ mean.indef.c + count_range + age.c + (1|SID), 
                    family = "binomial", data = indef.model)

#compare
anova(indef.base.single, indef.indef.single, test = 'LRT')
summary(indef.indef.single)

##add to final model with prod and math
#model without indefinite
indef.base <- glmer(Correct ~ mean.mf.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                    family = "binomial", data = indef.model)

#model with indefinite
indef.indef <- glmer(Correct ~ mean.indef.c + mean.mf.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                     family = "binomial", data = indef.model)

#compare
anova(indef.base, indef.indef, test = 'LRT') #mean indefinite significantly adds

summary(indef.indef)

```

##Indefinite visualization by Resilience
```{r}
all.data %>%
  filter(!is.na(mean.indef))%>%
  filter(Task == "SF")%>%
  mutate(indef.bin = ifelse(mean.indef < .25, "0 correct", 
                            ifelse(mean.indef == .25, "1 correct", 
                                   ifelse(mean.indef == .5, "2 correct", 
                                          ifelse(mean.indef == .75, "3 correct", "4 correct")))))%>%
  group_by(SID, Task, indef.bin)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = indef.bin, y = mean, fill=Task)) +
  # geom_violin(aes(fill = Task), alpha = .4) + 
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  geom_point(aes(x = indef.bin, y = mean, colour = Task),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1)+
  ylab("Mean Unit Task performance") + 
  xlab('Mean Indefinite Next Number performance') + 
  theme_bw(base_size = 15) + 
  theme(legend.position = "right") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "none") +
  ylim(0, 1.0) +
  scale_fill_manual(values = "#091E5B") + 
  scale_color_manual(values = "#091E5B") + 
  coord_fixed(ratio = 1.8)

# ggsave("~/Documents/Projects/sf_math/Analysis/indef.png")
```

##What about indefinite NN along with other tasks? 
```{r}
all.data %>%
  filter(!is.na(mean.indef))%>%
  filter(Task == "SF" | 
           Task == "WCN" | 
           Task == "MF" | 
           Task == "Indefinite")%>%
  group_by(SID, Task, sf.quartile)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = sf.quartile, y = mean, fill=Task)) +
  # geom_violin(aes(fill = Task), alpha = .4) + 
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  geom_point(aes(x = sf.quartile, y = mean, colour = Task),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1)+
  ylab("Mean Task performance") + 
  xlab("Unit Task quartiles") + 
  facet_grid(~sf.quartile, scale = "free_x") +
  theme_bw(base_size = 15) + 
  theme(legend.position = "right") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "none") +
  ylim(0, 1.0) 
  # scale_fill_manual(values = "#091E5B") + 
  # scale_color_manual(values = "#091E5B") 
  
```

***

##Mean Math Facts and Next Number by Unit Task performance
```{r}
all.data %>%
  distinct(SID, mean.unit, mean.mf)%>%
  ggplot(aes(x = mean.mf, y = mean.unit, colour = "#ed7d31")) + 
  geom_count(stat = "sum", show.legend = FALSE) + 
  geom_smooth(aes(fill = "#ed7d31"), alpha = .3, method = 'lm', 
              show.legend = FALSE) + 
  scale_color_manual(values = "#ed7d31") + 
  scale_fill_manual(values = "#ed7d31") +
  labs(x = "Mean Math Facts performance", 
       y = "Mean Unit Task performance") + 
  coord_fixed()

ggsave("~/Documents/Projects/sf_math/Analysis/MF_Unit.png")
  
```

#Mean unit by FHC
```{r}
all.data %>%
  distinct(SID, mean.unit, FHC)%>%
  ggplot(aes(x = FHC, y = mean.unit, color = "#173BAB")) + 
  geom_count(stat = "sum", show.legend = FALSE) + 
  geom_smooth(aes(fill = "#173BAB"), method = 'lm', alpha = .3, show.legend = FALSE) + 
  scale_color_manual(values = "#173BAB") + 
  scale_fill_manual(values = "#173BAB") + 
  labs(x = 'Final Highest Count', y = 'Mean Unit Task performance') +
  scale_x_continuous(breaks = seq(0, 120, 10)) + 
  coord_fixed(ratio = 120)

ggsave("~/Documents/Projects/sf_math/Analysis/FHC_unit.png")
```

#Mean Unit by HCNN
```{r}
all.data %>%
  mutate(highest_contig = factor(highest_contig, levels = c("0", "1", 
                                                            "7", "24", "26", "30", "62", 
                                                            "71", "83", "95")))%>%
  mutate(highest_contig.num = as.numeric(highest_contig))%>%
  distinct(SID, mean.unit, highest_contig, highest_contig.num)%>%
  ggplot(aes(x = highest_contig.num, y = mean.unit, color = "#3AAADD")) + 
  geom_count(stat = "sum", 
             show.legend = FALSE) + 
  geom_smooth(aes(fill = "#3AAADD"), alpha = .3, method = "lm", 
              show.legend = FALSE) + 
  scale_color_manual(values = "#3AAADD") + 
  scale_fill_manual(values = "#3AAADD") + 
  labs(x = 'Highest Contiguous Next Number', 
       y = "Mean Unit Task performance") + 
    scale_x_continuous(breaks = (1:length(as.numeric(levels(factor(all.data$highest_contig, levels = c("0", "1", 
                                                            "7", "24", "26", "30", "62", 
                                                            "71", "83", "95")))))), 
                     labels = as.character(levels(factor(all.data$highest_contig, levels = c("0", "1", 
                                                            "7", "24", "26", "30", "62", 
                                                            "71", "83", "95"))))) + 
  coord_fixed(ratio = 10)

ggsave("~/Documents/Projects/sf_math/Analysis/hcnn_unit.png")

# all.data %>%
#   filter(Task == "SF")%>%
#   group_by(SID, factor(highest_contig)))%>%
#   summarise(mean.sub = mean(Correct, na.rm = TRUE), 
#             n = n(), 
#             sd = sd(Correct, na.rm = TRUE), 
#             se = sd/sqrt(n))%>%
#   group_by(highest_contig)%>%
#   summarise(mean = mean(mean.sub), 
#             mean.se = mean(se)) %>%
#   ggplot(aes(x = highest_contig, y = ))
```

#Unit Task
##With individual prod points
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Unit Task performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

##By productivity and count range
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, count_range, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  geom_violin(aes(colour = Productive, fill = Productive), alpha = .1, size = 1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Productive), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE, size = 1) +
  ylab("Mean Unit Task performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") + 
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) + 
  scale_colour_manual(values = productivity.pal) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank())
  
```

***

#NN Task
###With individual prod points
```{r}
all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Next Number performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

##By productivity and count range
```{r}
all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID, count_range, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  geom_violin(aes(colour = Productive, fill = Productive), alpha = .1, size = 1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Productive), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE, size = 1) +
  ylab("Mean Next Number performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") + 
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) + 
  scale_colour_manual(values = productivity.pal) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank())
```

***

#Math Facts
##With individual prod points
```{r}
all.data %>%
  filter(Task == "MF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Math Facts performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

##By productivity and count range
```{r}
all.data %>%
  filter(Task == "MF")%>%
  group_by(SID, count_range, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  geom_violin(aes(colour = Productive, fill = Productive), alpha = .1, size = 1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Productive), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE, size = 1) +
  ylab("Mean Math Facts performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") + 
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) + 
  scale_colour_manual(values = productivity.pal) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank())
  
```

***

#Indefinite
##With individual prod points
NB, this does not include all participants.
```{r}
all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Indefinite performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

***

#Unit, NN, and MF together
##With individual prod points
```{r}


#now for just kids at ceiling
tmp <- all.data %>%
  mutate(sf.quartile = cut(mean.unit, 
                                breaks=quantile(mean.unit, na.rm=TRUE), 
                                include.lowest=TRUE))%>%
  mutate(mf.ceiling = ifelse(mean.mf >= .75, ">= 75% correct", "< 75% correct"))


tmp %>%
    filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF", 
           sf.quartile == "(0.875,1]")%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit Task", "Next Number", "Math Facts")))%>%
  group_by(SID, Task)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Task, y = mean, fill=Task)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  # geom_violin(alpha = .5) +
  geom_point(aes(x = Task, y = mean, colour = Task),
               position=position_jitter(width = .18, height = .035),
               size=1.5,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1)+
  ylab("Mean task performance") + 
  xlab('Task') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = three.pal, guide = "none") +
  scale_colour_manual(values = three.pal, guide = "none")

ggsave("~/Documents/Projects/sf_math/Analysis/all_tasks_ceiling.png", width = 5.25, height = 4.5)
```

##By productivity and count range (this needs a little work)
```{r}
all.data %>%
  filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF")%>%
  group_by(SID, count_range, Task, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  # geom_point(position=position_jitterdodge(jitter.width = .3, 
  #                                          jitter.height = .1, 
  #                                          dodge.width = .9),
  #            aes(colour = Productive, group=Productive), 
  #            size=1.5,
  #            alpha = .9,
  #              show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") + 
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2") + 
  # scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank()) + 
  facet_grid(~Task)
  
```

#Mean performance by item by task
```{r}
##For all tasks, by item
all.data %>%
  filter(Task == "MF" | 
         Task == "WCN" | 
           Task == "SF")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "6", "7", "15", "20", 
                                                  "21", "24", "26", "30", "32", 
                                                  "34", "46", "51", "57", "60", "62", "64", 
                                                  "71", "73", "81", "83", "84", "86",
                                                  "93", "95")), 
         Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit", 
                                                                       "Next Number", 
                                                                       "Math Facts")))%>%
  group_by(Productive, Task, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Productive, group = Productive)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  facet_grid(~Task, scale = "free_x") +
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  labs(x = "Number queried", y = "Mean performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
  
```


##Mean Unit task performance by HCNN
```{r}
all.data %>%
  filter(Task == "SF")%>%
  mutate(highest_contig = factor(highest_contig, levels = c("0", "1", "7", "24", "26", "30", 
                                                             "62", "71", "83", "95")))%>%
  group_by(highest_contig)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = highest_contig, y = mean, group= highest_contig)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  langcog::scale_color_solarized() +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  labs(x = "Highest contiguous NN", y = "Mean Unit Task performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

##Unit task by mean MF
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, mean.mf)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = mean.mf, y = mean_unit)) +
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_jitter()
```


#Correlations
```{r}
sub.dat <- all.data %>%
  distinct(SID, Age, IHC, FHC, mean.unit, mean.mf, mean.nn, highest_contig, highest_num)%>%
  dplyr::select(-SID)%>%
  mutate(highest_contig = as.numeric(highest_contig))
  
library(corrplot)

M<-cor(sub.dat)
head(round(M,2))

#add p values
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(sub.dat)
head(p.mat[, 1:8])

corrplot(M, type="upper", order="hclust", method = "color",
         addCoef.col = "white",
         tl.col="black", tl.srt=45,
         p.mat = p.mat, sig.level = 0.01)

```

---



---








##Attempting to visualize these models  
```{r}
# library(dotwhisker)
#visualizing regressions
full.model <- summary(sf.large.plusmf)

AIC <- as.numeric(full.model$AICtab[1])

full.model.df <- data.frame(coef(full.model)[,0:4])
full.model.df <- add_rownames(full.model.df, "Parameter")

full.model.df %<>%
  mutate(Parameter = ifelse(Parameter == "highest_contig.c", "HCNN",
                            ifelse(Parameter == "fhc.c", "FHC",
                                   ifelse(Parameter == "count_rangeOutside", "Beyond IHC",
                                          ifelse(Parameter == "age.c", "Age", 
                                                 ifelse(Parameter == "mean.mf.c", "Math Facts", "Intercept"))))))%>%
  mutate(Parameter = factor(Parameter, levels = c("Age","Beyond IHC", "Math Facts", "FHC", "HCNN", "Intercept"), 
                             labels = c("Age", "Within Initial Count",
                                        "Math Facts",  "Final Highest Count", "Highest Contig. Next Number",
                                         "Intercept")))

full.model.df %>%
ggplot(aes(x = Parameter, y = Estimate)) +
  geom_pointrange(aes(ymin = Estimate - 1.96 * Std..Error,
                      ymax = Estimate + 1.96 * Std..Error,
                      colour = Parameter), size = .85) +
  geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
  theme_bw(base_size = 13.5) +
  theme(panel.grid = element_blank(), 
        legend.position = "none") +
  coord_flip() +
  langcog::scale_color_solarized() +
  xlab("") +
  scale_y_continuous(name = "Coefficient Estimate (log likelihood)")
ggsave("~/Documents/Projects/sf_math/Analysis/coefficients.png", width = 5.75, height = 3.25)
```



#Post-hoc: SF and MF comparison


##Mean performance in each task by Unit Task quartile (SF, MF, NN)
```{r}


```

#Accuracy by Task - collapsed across all counters
```{r}
model.tasks.df <- tmp %>%
  filter(Task == "SF" | 
           Task == "WCN" | 
           Task == "MF") %>%
   mutate(highest_contig = as.integer(highest_contig), 
          Task = factor(Task, levels = c("SF", "WCN", "MF")),
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))

#LOOK AT JUST CEILING
#base model 
model.tasks.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial",
                         data = subset(model.tasks.df, sf.quartile == "(0.875,1]"))

#does performance significant differ by task? 
model.tasks.1 <- glmer(Correct ~ Task + count_range + age.c + (1|SID), family = "binomial", 
                      data = subset(model.tasks.df, sf.quartile == "(0.875,1]"))

#compare
anova(model.tasks.base, model.tasks.1, test= 'LRT') #yes, tasks adds

summary(model.tasks.1)

#Now look at all kids
  #base model 
  model.tasks.base.all <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial",
                           data = model.tasks.df)
  
  #does performance significant differ by task? 
  model.tasks.1.all <- glmer(Correct ~ Task + count_range + age.c + (1|SID), family = "binomial", 
                        data = model.tasks.df)
  
  #compare
  anova(model.tasks.base.all, model.tasks.1.all, test= 'LRT') #yes, tasks adds
  
  summary(model.tasks.1.all)

```

##For top quartile, t-test of mean MF and SF performance
```{r}
#for top quantile, t-test of mf and sf performance
ms <- tmp %>%
  group_by(SID, sf.quartile, Task)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  filter(sf.quartile == '(0.875,1]')

t.test(subset(ms, sf.quartile == '(0.875,1]' & Task == "MF")$mean, 
       subset(ms, sf.quartile == '(0.875,1]' & Task == "SF")$mean, var.equal = TRUE)
```

##T-test between mean SF and NN performance for top quartile
```{r}
#what about for next number?
ms <- tmp %>%
  group_by(SID, sf.quartile, Task)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  filter(sf.quartile == '(0.875,1]')

t.test(subset(ms, sf.quartile == '(0.875,1]' & Task == "WCN")$mean, 
       subset(ms, sf.quartile == '(0.875,1]' & Task == "SF")$mean, var.equal = TRUE)
```

##Exploratory - does mean indefinite performance predict SF? 
```{r}

task.pal2 <- c("#2aa198")
               
indef.model <- model.df %>%
  filter(!is.na(mean.indef.c))

indef.base <- glmer(Correct ~ mean.mf.c + highest_contig.c + count_range + age.c + (1|SID), 
                    family = "binomial", data = indef.model)

indef.indef <- glmer(Correct ~ mean.indef.c + mean.mf.c + highest_contig.c + count_range + age.c + (1|SID), 
                     family = "binomial", data = indef.model)

#compare
anova(indef.base, indef.indef, test = 'LRT')

summary(indef.indef)

##visualize
indef.model %>%
  group_by(SID, mean.indef)%>%
  summarise(mean.sf = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = mean.indef, y = mean.sf)) + 
  geom_point(position = position_jitter(width = .01, height = .01)) + 
  geom_smooth() +
  theme_bw()

#making the graph I want
tmp.df <- all.data %>%
  dplyr::select(SID, Age, Task, Correct)%>%
  filter(Task == "SF" | 
           Task == "MF" | 
           Task == "WCN")%>%
  group_by(SID, Task)%>%
  summarise(Mean = mean(Correct, na.rm = TRUE))

mean.indef <- all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID)%>%
  summarise(mean.indef = mean(Correct))

ms.tmp <- right_join(tmp.df, mean.indef, by = "SID")

all.data %>%
  filter(!is.na(mean.indef))%>%
  filter(Task == "SF")%>%
  mutate(indef.bin = ifelse((mean.indef <.25 & mean.indef <= .5), "0% — 50%", "50% — 100"))%>%
  group_by(SID, Task, indef.bin)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = indef.bin, y = mean, fill=Task)) +
  geom_violin(aes(fill = Task), alpha = .4) + 
  geom_point(aes(x = indef.bin, y = mean, colour = Task),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1)+
  ylab("Mean Unit Task performance") + 
  xlab('Mean Indefinite Next Number performance') + 
  theme_bw(base_size = 15) + 
  theme(legend.position = "right") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "none") +
  ylim(0, 1.0) +
  scale_fill_manual(values = "#091E5B") + 
  scale_color_manual(values = "#091E5B") + 
  coord_fixed(ratio = 1.8)

ggsave("~/Documents/Projects/sf_math/Analysis/indef.png")
```

##Post-hoc: Predicting mean performance by task, controlling for age and starting number
For children who are at ceiling in SF task, is there evidence that they draw upon one source of information more strongly than the other? If they generalize the SF from '+1' operation and from productive counting knowledge, then for children at ceiling there should no difference between these two tasks. If children weight one source of information more strongly, however, we should find a significant effect of task when controlling for starting number and age.
```{r}
ms1 <- tmp %>%
  filter(sf.quartile == "(0.875,1]", 
         Task=="MF" | 
           Task == "WCN")%>%
  mutate(starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))

summary(lmer(Correct ~ Task + starting_num.c + Age + (1|SID), 
              data = ms1))
```


```{r, include = FALSE}
indef.model <- model.df %>%
  filter(!is.na(mean.indef))

sf.indef.base <- glmer(Correct ~ count_range + age.c + (1|SID), 
                       family = "binomial", data = indef.model)
sf.indef <- glmer(Correct ~ mean.indef + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)

#test
anova(sf.indef.base, sf.indef, test = 'LRT')

#what about FHC and HCNN
sf.indef.fhc <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.base, sf.indef.fhc, test = 'LRT')

sf.indef.highest_contig <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.base, sf.indef.highest_contig, test = 'LRT')

#does HCNN add to this - yes
sf.indef.highest_contig.indef <- glmer(Correct ~ mean.indef + highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.highest_contig, sf.indef.highest_contig.indef, test = 'LRT')

#does fhc add to this
sf.indef.highest_contig.indef.fhc <- glmer(Correct ~ fhc.c + mean.indef + highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.highest_contig.indef, sf.indef.highest_contig.indef.fhc, test = 'LRT') #yes

#what about the addition of math facts
#individual model
sf.indef.mf <- glmer(Correct ~ mean.mf + count_range + age.c + (1|SID), 
                     family = "binomial", data = indef.model)
anova(sf.indef.base, sf.indef.mf, test = 'LRT')

#add to large model
sf.indef.highest_contig.indef.fhc.mf <- glmer(Correct ~ mean.mf + fhc.c + mean.indef + highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.highest_contig.indef.fhc, sf.indef.highest_contig.indef.fhc.mf, test = 'LRT')
```



