---
title: "SF-Math analysis"
author: "Rose Schneider"
date: "5/13/2018"
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
rm(list = ls())
require("knitr")
opts_knit$set(root.dir = "~/Documents/Projects/sf_math/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

#Description
Analysis code for project testing two hypothesized causal mechanisms in children's acquisition of the successor function: productive counting knowledge (i.e., mastery of recursive nature of number), and arithmetic operations (i.e., '+1' operation). At around 5.5-6 years of age, children exhibit a generalized understanding of the successor function, in that they seem to understand for every number its successor can be obtained by adding 1 (Cheung, Rubenson, & Barner, 2017; Davidson, Eng, & Barner, 2012). While previous work has found a link between successor knowledge and counting mastery, the exact nature of this link is unclear. Here, we are testing two hypothesis for how children might acquire the successor function: 

1.  Productive counting knowledge: Through mastering the base-system, children may notice that the next number in the base is generated through implementation of the successor function. Thus, the successor function is not linked merely to how high a child can count, but specifically their understanding of the recursive nature of number. 
2.  'Math Facts': Alternatively, in the course of learning arithmetic facts such as *4+1=5* and *5+1=6*, children may hypothesize that this '+1' rule holds true for any number. In this case, children may generalize the successor function through explicitly trained arithmetic language and procedures. 

Per our preregistration, we are testing whether productive counting knowledge (operationalized by 4 different measures, below) or 'Math Facts' performance significantly explain unique variance in children's knowledge of the successor function. We are doing so using model comparison, testing whether an added variable significantly improves the fit of the model in comparison to a base. 

It is important to note that our two hypotheses are not mutually exclusive: Given that previous work has found a positive correlation between age, counting ability, and successor knowledge (Cheung et al., 2017), it is possible that children's counting knowledge, arithmetic performance, and successor knowledge will be similarly correlated. Thus, per our preregistration, both productive counting knowledge and arithmetic performance may explain unique variance in children's successor knowledge. One important note, however, is that if the successor function is acquired through a generalization made over the '+1' operation, we should find that children who are at ceiling in our successor task should similarly be at ceiling in the 'Math Facts' task, as this hypothesis proposes that children are generalizing from that trained operation. 

##Methods
We tested 144 participants, aged 3;6-5;11, on 5/6 tasks: 

1.  Give-N (6, 9, 7, 5): Used to assess whether children are Cardinal Principle-knowers. Non CP-knowers excluded. 
2.  Highest Count with prompts: Children were asked to count as high as they could. If children could not remember the next number, or made an error, the experimenter provided that number, saying "Actually, what comes after *N* is *N+1*." Children were allowed 12 total errors, with a maximum of 3 errors per decade. 
3.  Successor task: Children saw some number of fish swim under a lilypad, hearing "Look! There are *N* fish in the pond." Children then saw one fish added to the pond (in full view of the child), and heard "Are there *N+1* or *N+2* fish now?" Order of alternatives was counterbalanced across trials, and children received 16 test trials, with numbers ranging from 5-95. 
4.  Next number task: Children heard a prompt "*N*, what comes next?" and needed to provide the next number. 8 test trials.
5.  Math Facts task: Children were asked verbally, "Do you know what *N*+1 is?". 8 test trials.
6.  Indefinite number task: Not all children received this task, included as an exploratory measure. Next number task for large/imaginary numbers (e.g., "Zillion 41, what comes next?")

In all instances, if a child did not respond the trial was excluded. If a child responded "I don't know," that trial was marked as incorrect. Valid answers were considered to be numeric responses. 

###Measures of productive counting knowledge/Math Facts
Different models of counting productivity have different predictions of which measure best determines when children can be classified as understanding the productive nature of the count list. As an empirical comparison of these measures has yet to be performed, it is unclear which of these four (non-mutually-exclusive) alternatives is the best measure of productivity; thus, we will be testing the relationship between Successor Performance and each of these four measures individually.

1.  Initial Highest Count (IHC): The highest number reached in the Highest Count Task prior to making an error
2.  Final Highest Count (FHC): The highest number reached in the Highest Count Task at the end of the task (with or without prompts)
3.  Highest Next Number (HNN): The highest number for which a child can generate a successor in the Next Number Task 
4.  Productivity: A binary classification we derived. A child is classified as "Productive" if they are able to count at least 2 decades past an error without making more than 3 errors within those 2 decades. 

'Math Facts' measure: Mean performance on 'Math Facts' task. 

---

#Setup
##Loading data
```{r}
data.raw <- read.csv("~/Documents/Projects/sf_math/Data/sf_math_data.csv")%>%
  filter(SID != "CopyPasteMe", 
         SID != "?")%>%
  droplevels()%>%
  filter(Correct != "HELP")%>% #temporary while we resolve helps
  mutate(Age = as.numeric(as.character(Age)),
         Correct = as.integer(as.character(Correct)))%>%
  mutate(Age = round(Age, 2))%>%
  dplyr::select(-Response_single, -Response_double)%>% #remove double coding
  dplyr::rename(Response = Response_final) #rename for code

hc.df <- read.csv("~/Documents/Projects/sf_math/Data/sf_math_hc.csv")%>%
  dplyr::select(-IHC_single, - FHC_single, -Special_count, -Notes, -RMS.note)%>%
  filter(Exclude_trial != 1, 
         IHC_final != "HELP", 
         FHC_final != "HELP")%>%
  dplyr::rename(FHC = FHC_final, 
                IHC = IHC_final)%>%
  filter(!is.na(FHC), 
         !is.na(IHC))%>%
  mutate(IHC = ifelse(as.integer(as.character(IHC)) > 120, 120, as.integer(as.character(IHC))), 
         FHC = ifelse(as.integer(as.character(FHC)) > 120, 120, as.integer(as.character(FHC)))) #add cap to IHC and FHC
```

---

#Data manipulations
##Productive/Nonproductive
Children are classified as Productive if they are able to count at least 2 decades past an error without making more than 3 errors within those 2 decades. 
```{r}
hc <- hc.df %>% 
  dplyr::select(SID, Last_successful, IHC, FHC) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% 
  mutate(Last_successful = ifelse(is.na(Last_successful), 120, Last_successful))%>%
  mutate(SID = as.character(SID))
# 
# 
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 120){
    # if they get to 120 on first try, = productive
    return("Productive")
  } else if(subject$FHC[1] == 120 & nrow(subject) < 4) {
    return("Productive")
  } else if(subject$FHC[1] < 120 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return("Nonproductive")
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return("Productive")
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return("Productive") # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return("Nonproductive") # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return("Nonproductive")
  }
}

# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    # print(i) # for debugging
    names(prod.class) <- c("SID", "productive")
    prod.class %<>%
      mutate(SID = as.character(SID), 
             productive = as.character(productive))
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

#get productive classification for every participant
productive <- class_prod(unique_SIDs)%>%
  dplyr::rename(Productive = productive)

#remove last-successful from hc so you can add IHC and FHC to data.raw
hc %<>%
  dplyr::select(-Last_successful)

#add productive classifications
productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, Productive)

#full join with raw data
data.raw <- full_join(data.raw, productive, by = "SID") 

#made SID and Productive factors again #MSaPFA
data.raw %<>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive))
```

##Knower level
Children are classified as CP-knowers if they get all 4 CP items correct. Otherwise, they are classified as subset-knowers. This is for a sanity check - all kids in this dataset are CP-knowers.
```{r}
cp.df <- data.raw %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct, na.rm = TRUE))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  dplyr::select(-sum_correct)

data.raw <- full_join(data.raw, cp.df, by = "SID")
```

##Highest Contiguous NN (HCNN)
Highest contiguous NN = highest number successfully generated, provided that previous numbers were correct. Children who failed training given HCNN of 0 (N = 2). 

Although we initially preregistered Highest Next Number, we realized that this measure might be skewed because it did not account for accuracy. We are including post-hoc analyses with HCNN as a more accurate measure of productive counting knowledge. 
```{r}
#Get kids who failed NN for highest contiguous
failed.nn <- data.raw %>%
  filter(Task == "WCN", 
         Correct == 0, 
         Trial_number == "Training")

failed.nn.sids <- unique(as.vector(failed.nn$SID))

#get unique ids
unique.nn <- data.raw %>%
  filter(Task == "WCN")%>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(7, 26, 30, 62, 83, 95, 71, 24))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- data.raw %>%
      filter(Task == "WCN",
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item= as.integer(as.character(Task_item)))%>%
      mutate(Task_item = sort(as.integer(as.character(Task_item))))
    if (length(tmp$SID) == 0) {
      highest_contig = 95
      sub_contig <- data.frame(sub, highest_contig) 
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig) 
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(as.integer(as.character(tmp$Task_item))) == 7) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(as.integer(as.character(tmp$Task_item)))
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig) 
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    }
  }
  contig %<>%
    mutate(highest_contig = as.character(highest_contig))
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
data.raw <- full_join(data.raw, highest_contiguous_nn, by = "SID")

# #how many kids don't have a highest contiguous NN? 
# all.data %>%
#   filter(is.na(Language))
#   filter(is.na(highest_contig))%>%
#   distinct(Language, SID)%>%
#   group_by(Language)%>%
#   summarise(n = n())%>%
#   kable()

#Check - does anyone have NA for HCNN? 
data.raw %>%
  filter(is.na(highest_contig))%>%
  filter(Exclude_analysis == 0)
```

---

#Exclusions 
##Global exclusions
Children were excluded from the analysis only if a) they did not complete the highest count task or Give N, or b) their exclusion was noted by the experimenter. 

Pre-exclusion kids
```{r}
##How many kids pre-exclusions?
data.raw %>%
  distinct(SID)%>%
  summarise(n = n())%>%
  kable()
```

Exclusion reasons
```{r}
#Why are kids being excluded?
data.raw %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis, Exclude_analysis_reason)%>%
  group_by(Exclude_analysis_reason)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n)) %>%
  kable()
```

```{r}
#exclude these kids from analysis
all.data <- data.raw %>%
  filter(Exclude_analysis != 1)
```

How many kids left after exclusions?
```{r}
#How many kids are left after exclusions
all.data %>%
  distinct(SID)%>%
  summarise(n = n())%>%
  mutate(total.n = sum(n))%>%
  kable()
```

Sex
```{r}
all.data %>%
  distinct(SID, Sex)%>%
  group_by(Sex)%>%
  summarise(n = n())
```

Age histogram
```{r}
#histogram of age
all.data %>%
  distinct(SID, Age)%>%
ggplot(aes(x = Age)) +
  geom_histogram(binwidth = .5, colour = "black") +
  theme_bw() + 
  theme(panel.grid.minor = element_blank()) +
  scale_x_continuous(breaks = c(3.5, 4, 4.5, 5, 5.5, 6.1)) +
  scale_fill_brewer(palette = "Dark2") + 
  guides(fill = FALSE) +
  labs(y = "Count")

#demographics
all.data %>%
  distinct(SID, Age)%>%
  summarise(mean_age = round(mean(Age), 2), 
            sd_age = round(sd(Age), 2))%>%
  kable()
```

###Task exclusions
Children were excluded from a given task if they did not complete at least ONE trials of that task (in addition to the training trial). In order to be considered as having completed a trial of the task, a child must at least say "I don't know."  These children were excluded manually.
```{r}
#how many kids are excluded from which tasks
all.data %>%
  filter(Exclude_task == 1)%>%
  distinct(SID, Exclude_task, Excluded_task, Exclude_task_reason)%>%
  kable()

#exclude
all.data %<>%
  filter(Exclude_task != 1)
```

##Excluded trials
Trials where a participant gave no response were excluded from analysis.

How many trials were excluded? Why?
```{r}
#how many trials excluded, and for what reason
all.data %>%
  filter(Exclude_trial == "1")%>%
  group_by(Task, Exclude_trial_reason)%>%
  summarise(n = n())%>%
  kable()

#exclude these trials
all.data %<>%
  filter(Exclude_trial != "1")
```

How many kids failed training? In what task?
```{r}
#how many kids failed training
all.data %>%
  filter(Trial_number == "Training", #note that only one kid failed first trial of SF, no kid failed all
         Correct == 0)%>%
  group_by(Task)%>%
  summarise(n = n()) %>%
  kable()

#filter out training trials 
all.data %<>%
  filter(Trial_number != "Training")

#how many trials do we have for each task?
all.data %>%
  filter(Task == "SF" | 
         Task == "WCN" |
           Task == "MF")%>%
  group_by(Task)%>%
  summarise(n = n()) %>%
  kable()
```

---
#More classifications (post exclusion)

##Within/outside count range
Each trial on the Unit or WCN task was determined to be either within or outside a child's unprompted count range (IHC).
```{r}
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "WCN" | Task == "MF") & as.numeric(as.character(Task_item)) <= IHC, "Within", "Outside")) %>%
  mutate(count_range = factor(count_range, levels = c("Within", "Outside")))
```

##Highest next number (HNN) - not using this anymore
Find the highest next number answered correctly for each participant.
```{r}
# #Create a lookup table with the highest NN correctly answered
# lookup <- all.data %>%
#   filter(Task == "WCN")%>%
#   filter(Correct == 1)%>%
#   group_by(SID)%>%
#   summarise(max = max(as.integer(as.character(Task_item))))
# 
# no.corr.nn <- all.data %>%
#   filter(Task == "WCN")%>%
#   group_by(SID)%>%
#   summarise(mean = mean(Correct, na.rm = TRUE))%>%
#   filter(mean == 0)
# 
# no.corr.nn.sids <- as.vector(unique(no.corr.nn$SID))
# 
# #Function that adds the highest NN to a participant's row in the SF dataframe
# add_highest_num <- function(df) {
#   tmp <- df
#   for (row in 1:nrow(tmp)) {
#     sub = as.character(tmp[row, "SID"])
#     if (sub %in% no.corr.nn.sids) {
#       highest_num = 0
#       tmp[row, "highest_num"] = highest_num
#     } else {
#       highest_num = subset(lookup, SID == sub)$max
#       tmp[row, "highest_num"] = highest_num
#     }
#   }
#   return(tmp)
# }
# 
# #run this function on SF dataframe
# all.data <- add_highest_num(all.data)
# ```
# 
# ##Productivity gradient
# Exploratory measure of productivity. Accounts for recursive counting knowledge while attempting to disentangle the effects of Initial Highest Count and Final Highest Count. Productivity gradient is calculated by dividing the delta between IHC and FHC by the total number of numbers left in the task by subtracting the IHC from 120. 
# ```{r}
# all.data %<>%
#   mutate(delta.hc = FHC-IHC, 
#          prod.gradient = delta.hc/(120-IHC), 
#          prod.gradient = ifelse(IHC == 120 | IHC == 119, 1, as.numeric(prod.gradient)))
```

##Mean Indefinite number performance
Mean performance on the indefinite number task for children who received it.
```{r}
indef.mean <- all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID)%>%
  summarise(mean.indef = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, indef.mean, by = "SID")
```


##Mean Math Facts performance, Mean NN performance, Mean successor Performance
Mean performance on Math Facts, Next Number, and Successor task.
```{r}
mf.sum <- all.data %>%
  filter(Task == "MF")%>%
  group_by(SID)%>%
  summarise(mean.mf = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, mf.sum, by = "SID")

sf.mean <- all.data %>%
  filter(Task == "SF")%>%
  group_by(SID)%>%
  summarise(mean.unit = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, sf.mean, by = "SID")

nn.mean <- all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID)%>%
  summarise(mean.nn = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, nn.mean, by = "SID")
```

##Demographics
```{r}
all.data %>%
  distinct(SID, Age)%>%
  summarise(mean = round(mean(Age), 2), 
            sd = round(sd(Age), 2))%>%
  kable()

#sex
all.data %>%
  distinct(SID, Sex)%>%
  group_by(Sex)%>%
  summarise(n = n())%>%
  kable()
```

---

#Primary analyses
17.1 Counting Productivity &amp; Successor Task Performance: To identify whether there is connection between counting experience and Successor Task performance, we will conduct three initial analyses, predicting Successor Task performance from either (1) Initial Highest Count, (2) Productivity (defined above), (3) final highest count, or (4) performance on the Next Number task.

All models will be logistic mixed effects models, predicting performance on a trial as a function of the following
predictors, with a random intercept for subject. In R, the formula will be glmer(SF_correct ~ (predictor) + age + (1|subject), family = binomial).
Simple Models
-  Model 1: Successor.Performance ~ Highest.Next.Number + Within/Outside range + Age + (1|subject)
-  Model 2: Successor.Performance ~ Initial.Count + Within/Outside range + Age + (1|subject)
-  Model 3: Successor.Performance ~ Final.Count + Within/Outside range + Age + (1|subject)
-  Model 4: Successor.Performance ~ Productivity+ Within/Outside range + Age + (1|subject)

After running these first four models, any predictor that significantly (p &lt;.05) predicted Successor Performance will be added into Model 5, which will be our “Large” model (containing all predictors that significantly predicted Successor Performance in the simple models).

We will construct model 5 hierarchically. Model comparisons will be performed at each stage by running a likelihood ratio test between reduced and full models, with significant effects retained in the full model (Model 5). Model selection will be done on the basis of AIC evaluation and significant Chi-square statistic.

First, make the model df
```{r}
model.df <- all.data %>%
  mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         mean.indef.c = as.vector(scale(mean.indef, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(Task == "SF")
```

Make the models 
```{r}
#base
sf.base <- glmer(Correct ~ count_range  + age.c + (1|SID), 
                 family = "binomial", data = model.df)
# #highest nn
# sf.highest_nn <- glmer(Correct ~ highest_num.c + count_range + age.c + (1|SID), 
#                  family = "binomial", data = model.df)

#ihc
sf.ihc <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#fhc
sf.fhc <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Productive
sf.prod <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Highest contiguous NN
sf.highest_contig <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

# #Productivity gradient
# sf.prod.gradient <- glmer(Correct ~ prod.gradient + count_range + age.c + (1|SID), 
#                  family = "binomial", data = model.df)
```

##Regression table
```{r}
library(memisc)
mtable.sf <- mtable('Base Model' = sf.base,
            # 'Model 1: Highest NN' = sf.highest_nn,
            'Model 2: IHC' = sf.ihc,
            'Model 3: FHC' = sf.fhc,
            'Model 4: Productivity.' = sf.prod,
            'Model 5: HCNN' = sf.highest_contig,
            # 'Model 6: Prod. gradient' = sf.prod.gradient,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf

```

###Test of productivity predictor in comparison to base
```{r}
# #base v. highest nn
# anova(sf.base, sf.highest_nn, test = 'LRT')
#base v. ihc
anova(sf.base, sf.ihc, test = 'LRT')
#base v. fhc
anova(sf.base, sf.fhc, test = 'LRT')
#base v. productive
anova(sf.base, sf.prod, test = 'LRT')
#base v. highest_contig
anova(sf.base, sf.highest_contig, test = 'LRT')
# #base. v. prod. gradient
# anova(sf.base, sf.prod.gradient, test = 'LRT')
```

##Ordering of productivity predictor by AIC: 
HCNN: 2650.2
FHC: 2688.5
IHC: 2701.3
Productive: 2738.5


##Model comparisons: Large model (with HCNN)
Start with HCNN, strongest predictor.
```{r}
#HCNN
sf.large.base <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
summary(sf.large.base)

#HCNN + FHC
sf.large.plusfhc <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.base, sf.large.plusfhc, test = 'LRT') #FHC adds to this model

#IHC + FHC 
sf.large.plusihc <- glmer(Correct ~ ihc.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.plusfhc, sf.large.plusihc, test = 'LRT') #IHC does not add to this model

##Productivity + FHC
sf.large.plusprod <- glmer(Correct ~ Productive + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.plusfhc, sf.large.plusprod, test = 'LRT') #productivity does not add to this model 

##model table
mtable.sf.large <- mtable('Base Model: HCNN' = sf.large.base,
            'Model 1: FHC + HCNN' = sf.large.plusfhc,
            'Model 2: IHC + FHC + HCNN' = sf.large.plusihc,
            'Model 3: Prod. + FHC + HCNN' = sf.large.plusprod,
            summary.stats = c('Nagelkerke R-sq.','Log-likelihood','AIC','N'))
mtable.sf.large
```

#Math Facts model 
Is mean Math Facts performance significantly predictive of SF knowledge? Yes - Chisq(1) = 54.09, p < .0001
```{r}
#build model
sf.mf <- glmer(Correct ~ mean.mf.c + count_range + age.c + (1|SID), 
               family = "binomial", data = model.df)

#test
anova(sf.base, sf.mf, test = 'LRT')
mtable('Math Facts' = sf.mf)
```

##Model comparison, Math Facts + FHC + HCNN
Does Math Facts explain unique variance on top of FHC? 
Yes - added to a model with FHC & HCNN, mean math facts performance explains unique variance. 
```{r}
sf.large.plusmf <- glmer(Correct ~ mean.mf.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.plusfhc, sf.large.plusmf) #math facts significantly adds to the model

summary(sf.large.plusmf)
library(sjPlot)
tab_model(sf.large.plusmf, transform = NULL)
```

***

#Testing whether SF is generalized from Math Facts
If children are acquiring SF from MF, we should expect that all children who demonstrate mastery of SF (in top quartile), should similarly be at ceiling (or close to ceiling, >.75 mean performance) in MF. 

```{r}
#add quartiles for unit task
all.data %<>%
  mutate(sf.quartile = cut(mean.unit, 
                                breaks=quantile(mean.unit, na.rm=TRUE), 
                                include.lowest=TRUE))

##ANALYSIS
#Looking only at children who are at ceiling in the Unit Task, are they also at ceiling in the MF task?
model.mf.sf.ceiling.df <- all.data %>%
  filter(Task == "SF" | 
           Task == "WCN" |
           Task == "MF", 
         sf.quartile == "(0.875,1]")%>%
   mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         mean.indef.c = as.vector(scale(mean.indef, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  mutate(Task = factor(Task, levels = c("SF", "MF", "WCN")))

#make base model
mf.sf.ceiling.base <- glmer(Correct ~ count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.ceiling.df)
#now add task
mf.sf.ceiling.task <- glmer(Correct ~ Task + count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.ceiling.df)
#test to see if there is a difference by task 
anova(mf.sf.ceiling.base, mf.sf.ceiling.task, test = 'LRT') #yes, there is a significant effect of task

#summary
summary(mf.sf.ceiling.task)
```

###Follow up on the ceiling unit task analysis with an analysis which has all children
```{r}
model.mf.sf.all.df <- all.data %>%
  filter(Task == "SF" | 
           Task == "WCN" |
           Task == "MF")%>%
   mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         mean.indef.c = as.vector(scale(mean.indef, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  mutate(Task = factor(Task, levels = c("SF", "MF", "WCN")))

#make base model
mf.sf.all.base <- glmer(Correct ~ count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.all.df)
#now add task
mf.sf.all.task <- glmer(Correct ~ Task + count_range + age.c + (1|SID), 
                            family = "binomial", data = model.mf.sf.all.df)
#test to see if there is a difference by task 
anova(mf.sf.all.base, mf.sf.all.task, test = 'LRT') #yes, there is a significant effect of task

#summary
summary(mf.sf.all.task)

```

##Figure: Line graph showing difference in performance between NN and Math Facts as function of Unit Task quartile

```{r}
task.pal <- c("#3AAADD", "#ed7d31")
 
##MF performance by quartile
all.data %>% filter(Task == "WCN" |
           Task == "MF")%>%
  mutate(Task = factor(Task, levels = c("WCN", "MF"), 
                       labels = c("Next Number", "Math Facts")), 
         sf.quartile = factor(sf.quartile, labels = c("25% — 44%", "44% — 63%", "63% — 88%", "88% — 100%"))) %>% 
  group_by(SID, sf.quartile, Task)%>%
  summarise(mean.sub = mean(as.integer(as.character(Correct)), na.rm = TRUE), 
            n = n(), 
            sd = sd(as.integer(as.character(Correct)), na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  group_by(sf.quartile, Task)%>%
  summarise(mean = mean(mean.sub), 
            mean.se = mean(se))%>%
  ggplot(aes(x = sf.quartile, y = mean, color=Task, group = Task)) +
  geom_point(size = 2.75) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - mean.se, ymax = mean + mean.se), 
                width = .05, size = 1) +
  ylab("Mean task performance") + 
  xlab('Mean Unit Task performance') + 
  theme_bw(base_size = 15) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        legend.position = c(0.818, 0.2)) +
  ylim(0, 1.0) +
  scale_color_manual(values = task.pal)


ggsave("~/Documents/Projects/sf_math/Analysis/3_tasks.png", width = 6, height = 5)
```


##Alternative figure: Bar graph showing difference between MF and NN as function of SF
```{r}
three.pal <- c("#173BAB", "#5CA7D8", "#DE8141")

all.data %>%
  filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF")%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit Task", "Next Number", "Math Facts")), 
        sf.quartile = factor(sf.quartile, labels = c("25% — 44%", "44% — 63%", "63% — 88%", "88% — 100%")))%>%
  group_by(SID, Task, sf.quartile)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Task, y = mean, fill=Task)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  # geom_violin(alpha = .5) +
  geom_point(aes(x = Task, y = mean, colour = Task),
               position=position_jitter(width = .18, height = .035),
               size=1.5,
               show.legend=FALSE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, size = 1)+
  ylab("Mean task performance") + 
  xlab('Unit Task performance quartiles') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        legend.position = "top") +
  ylim(0, 1.0) +
  scale_fill_manual(values = three.pal) +
  scale_colour_manual(values = three.pal, guide = "none") + 
  facet_wrap(~sf.quartile, strip.position = "bottom", ncol = 4)

ggsave("~/Documents/Projects/sf_math/Analysis/all_tasks.png", width = 7, height = 4)
```

---

#Highest Count

Descriptives
```{r}
#rename productivity
all.data %<>%
  mutate(Productive = factor(Productive, levels = c("Productive", "Nonproductive"), 
                             labels = c("Resilient", "Non-Resilient")))

productivity.pal <- c("#00b8e6", "#666666")

all.data %>%
  distinct(SID, Age, Productive, IHC, FHC)%>%
  group_by(Productive)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC)), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC)), 
            mean_FHC = round(mean(FHC)), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC)))%>%
  kable()

#overall IHC and FHC
all.data %>%
  distinct(SID, Age, Productive, IHC, FHC)%>%
  summarise(n = n(),
            mean_IHC = round(mean(IHC)), 
            sd_IHC = round(sd(IHC), 2), 
            median_IHC = round(median(IHC)), 
            mean_FHC = round(mean(FHC)), 
            sd_FHC = round(sd(FHC), 2), 
            median_FHC = round(median(FHC)))%>%
  kable()
```

##Scatterplot/density of IHC/FHC
```{r}
initial_final <- all.data %>%
  filter(!is.na(Productive))%>%
  distinct(SID, IHC, FHC, Productive)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

library(ggstance)
library(ggjoy)
library(cowplot)
####Cantonese####
pmain <- ggplot(initial_final, aes(x = IHC, y = FHC, color = Productive, shape = Productive)) + 
  geom_point(size = 3, alpha = .8, position = position_jitter()) + 
  # geom_jitter() + 
  scale_color_manual(values = productivity.pal) + 
  coord_fixed() + 
  theme_bw(base_size = 15) +
  scale_x_continuous(breaks = seq(0, 120, 10)) + 
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.title = element_text(size = 12),
        legend.position = c(.75, 0.2), 
        legend.text = element_text(size = 10), 
        legend.title = element_blank(), 
        axis.text = element_text(size = 11)) + 
  labs(x = "Initial Highest Count", y = "Final Highest Count") 

xdens <- axis_canvas(pmain, axis = "x") + 
  # geom_ridgeline(data = us_initial, aes(x = IHC, y = 0, height=..density.., 
  #                                       fill = Productive), 
  #                stat = 'xdensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = initial_final, aes(x = IHC, y = ..density.., fill = Productive), 
               alpha=.4, adjust = .5) + 
  scale_fill_manual(values = productivity.pal) 

ydens <- axis_canvas(pmain, axis = "y", coord_flip = TRUE) + 
  # geom_vridgeline(data = us_initial, aes(y = FHC, x = 0, width=..density.., 
  #                                       fill = Productive), 
  #                stat = 'ydensity', alpha = .5, size = .2, trim = FALSE) + 
  geom_density(data = initial_final, aes(x = FHC, y = ..density.., fill = Productive), 
               alpha=.4, adjust = .5) +
  coord_flip() +
  scale_fill_manual(values = productivity.pal) 

p5 <- insert_xaxis_grob(pmain, xdens, grid::unit(.2, "null"), position = "top")
count_dens <- insert_yaxis_grob(p5, ydens, grid::unit(.2, "null"), position = "right")
ggdraw(count_dens)
ggsave("~/Documents/Projects/sf_math/Analysis/density.png")
# ggdraw(p6)
# png(filename = "hk_density.png")
# ggdraw(p6)
# dev.off()
```

###How many children who stopped before 120 were able to count at least a little beyond their IHC?
```{r}
#how many kids counted spontaneously to 120?
all.data %>%
  distinct(SID, IHC)%>%
  filter(IHC == 120)

error.freq %>%
  distinct(SID, IHC, FHC)%>%
  filter(IHC != 120)%>%
  mutate(delta.count = FHC-IHC, 
         counted.beyond = ifelse(delta.count > 0, "counted beyond IHC", "could not count beyond IHC"))%>%
  group_by(counted.beyond)%>%
  summarise(n = n(), 
            mean.delta = mean(delta.count))
```


Prompts by productivity
```{r}
#how many prompts do productive and nonproductive counters need? and what kind of errors do they make?
#bind productive and hc.df 
productive %<>% 
  dplyr::select(SID, Productive)

error.freq <- full_join(hc.df, productive, by = "SID")%>%
  filter(!is.na(Last_successful))%>%
  mutate(Error_type = ifelse(Last_successful %% 10 == 9 , "Decade end", 
                             ifelse(Last_successful %% 10 == 0, "Decade beginning", "Mid-decade")))

#mean number of prompts by Productivity
mean_prompts.type <- error.freq %>%
  group_by(Productive, Error_type)%>%
  summarise(n = n())%>%
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)
mean_prompts.type %>%
  kable()

```

##Where are errors happening?
```{r}
error.freq.decade <- error.freq %>%
  mutate(error.decade = ifelse(Last_successful < 10, 0, 
                               ifelse(Last_successful >= 10 & Last_successful < 20, 10, 
                                      ifelse(Last_successful >= 20 & Last_successful < 30, 20, 
                                             ifelse(Last_successful >= 30 & Last_successful < 40, 30, 
                                                    ifelse(Last_successful >=40 & Last_successful < 50, 40, 
                                                           ifelse(Last_successful >= 50 & Last_successful < 60, 50, 
                                                                  ifelse(Last_successful >= 60 & Last_successful < 70, 60, 
                                                                         ifelse(Last_successful >= 70 & Last_successful < 80, 70, 
                                                                                ifelse(Last_successful >= 80 & Last_successful < 90, 80, 
                                                                                       ifelse(Last_successful >= 90 & Last_successful < 100, 90, 
                                                                                              ifelse(Last_successful >= 100 & Last_successful < 110, 100, 110)))))))))))) %>%
  mutate(error.base = (error.decade - Last_successful) * -1, 
         error.base = ifelse(Last_successful == 120, 0, as.numeric(error.base)))
```


###Error by decade
```{r}
error.freq.decade %>%
  mutate(error.decade = factor(error.decade, levels = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 
                                                        90, 100, 110)),
         error.base = factor(error.base))%>%
  group_by(Productive, error.decade)%>%
  summarise(n = n())%>% 
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.decade, y = Productive)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 2.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 10) + 
  labs(x = "Decade of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())
```

###Error by unit
```{r}
error.freq.decade %>%
  filter(Last_successful <= 120)%>% #filter out trials where kid kept going beyond 140
  mutate(error.base = factor(error.base))%>%
  group_by(Productive, error.base)%>%
  summarise(n = n())%>% 
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
         prop = n/total.n)%>%
  mutate(n = ifelse(is.na(n), 0, as.numeric(n)))%>%
  ggplot(aes(x = error.base, y = Productive)) +
  geom_tile(aes(fill = round(prop, 2))) +
  geom_text(aes(label = as.character(round(prop, 2))), 
            size = 2.5) +
  coord_equal() +
  scale_fill_gradient2(low = "white", high = "red", "Proportion") + 
  theme_bw(base_size = 10) + 
  labs(x = "Unit of error") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "bottom", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())
```



##How many errors?
```{r}
error.freq %>%
  filter(Last_successful != 120)%>%
  group_by(SID)%>%
  summarise(n = n())%>%
  group_by()%>%
  summarise(mean_prompts = round(mean(n, na.rm = TRUE), 2),
            sd_prompts = round(sd(n, na.rm = TRUE), 2), 
            median_prompts = round(median(n, na.rm = TRUE), 2),
            max_prompt = max(n, na.rm = TRUE), 
            min_prompt = min(n, na.rm = TRUE))%>%
  kable()
```

###Histogram Initial and Final Highest Count
```{r}
productivity.pal <- c("#666666","#00b8e6")

unique.hc.data <- all.data %>%
  distinct(SID, IHC, FHC, Productive, Language, Dataset)%>%
  gather(IHC_FHC,highest_count, IHC:FHC)%>%
  mutate(highest_count = as.integer(highest_count), 
         IHC_FHC = factor(IHC_FHC, levels = c("IHC", "FHC"), 
                          labels = c("Initial Highest Count", "Final Highest Count")))

#Initial/Final
unique.hc.data %>%
ggplot(aes(x=highest_count, fill=Productive)) + 
  geom_histogram(binwidth = 10, colour = "black") +
  theme_bw(base_size = 10)+
  facet_grid(~IHC_FHC) +
  scale_x_continuous(breaks = seq(0, 140, 10))+
  scale_fill_manual(values = productivity.pal) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        panel.grid.minor = element_blank(), 
        legend.title = element_blank())+
  theme(legend.position = "bottom") + 
  labs(x = "Highest count", y = "Frequency")
```


####IHC/FHC scatter
```{r}
initial_final %>%
ggplot(aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = 1) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  theme_bw(base_size = 13) + 
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 8)) +
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

***

##Mean Math Facts and Next Number by Unit Task performance
```{r}
all.data %>%
  distinct(SID, mean.unit, mean.mf)%>%
  ggplot(aes(x = mean.mf, y = mean.unit, colour = "#ed7d31")) + 
  geom_count(stat = "sum", show.legend = FALSE) + 
  geom_smooth(aes(fill = "#ed7d31"), alpha = .3, method = 'lm', 
              show.legend = FALSE) + 
  scale_color_manual(values = "#ed7d31") + 
  scale_fill_manual(values = "#ed7d31") +
  labs(x = "Mean Math Facts performance", 
       y = "Mean Unit Task performance") + 
  coord_fixed()

ggsave("~/Documents/Projects/sf_math/Analysis/MF_Unit.png")
  
```

#Mean unit by FHC
```{r}
all.data %>%
  distinct(SID, mean.unit, FHC)%>%
  ggplot(aes(x = FHC, y = mean.unit, color = "#173BAB")) + 
  geom_count(stat = "sum", show.legend = FALSE) + 
  geom_smooth(aes(fill = "#173BAB"), method = 'lm', alpha = .3, show.legend = FALSE) + 
  scale_color_manual(values = "#173BAB") + 
  scale_fill_manual(values = "#173BAB") + 
  labs(x = 'Final Highest Count', y = 'Mean Unit Task performance') +
  scale_x_continuous(breaks = seq(0, 120, 10)) + 
  coord_fixed(ratio = 120)

ggsave("~/Documents/Projects/sf_math/Analysis/FHC_unit.png")
```

#Mean Unit by HCNN
```{r}
all.data %>%
  mutate(highest_contig = factor(highest_contig, levels = c("0", "1", 
                                                            "7", "24", "26", "30", "62", 
                                                            "71", "83", "95")))%>%
  mutate(highest_contig.num = as.numeric(highest_contig))%>%
  distinct(SID, mean.unit, highest_contig, highest_contig.num)%>%
  ggplot(aes(x = highest_contig.num, y = mean.unit, color = "#3AAADD")) + 
  geom_count(stat = "sum", 
             show.legend = FALSE) + 
  geom_smooth(aes(fill = "#3AAADD"), alpha = .3, method = "lm", 
              show.legend = FALSE) + 
  scale_color_manual(values = "#3AAADD") + 
  scale_fill_manual(values = "#3AAADD") + 
  labs(x = 'Highest Contiguous Next Number', 
       y = "Mean Unit Task performance") + 
    scale_x_continuous(breaks = (1:length(as.numeric(levels(factor(all.data$highest_contig, levels = c("0", "1", 
                                                            "7", "24", "26", "30", "62", 
                                                            "71", "83", "95")))))), 
                     labels = as.character(levels(factor(all.data$highest_contig, levels = c("0", "1", 
                                                            "7", "24", "26", "30", "62", 
                                                            "71", "83", "95"))))) + 
  coord_fixed(ratio = 10)

ggsave("~/Documents/Projects/sf_math/Analysis/hcnn_unit.png")

# all.data %>%
#   filter(Task == "SF")%>%
#   group_by(SID, factor(highest_contig)))%>%
#   summarise(mean.sub = mean(Correct, na.rm = TRUE), 
#             n = n(), 
#             sd = sd(Correct, na.rm = TRUE), 
#             se = sd/sqrt(n))%>%
#   group_by(highest_contig)%>%
#   summarise(mean = mean(mean.sub), 
#             mean.se = mean(se)) %>%
#   ggplot(aes(x = highest_contig, y = ))
```

#Unit Task
##With individual prod points
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Unit Task performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

##By productivity and count range
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, count_range, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  geom_violin(aes(colour = Productive, fill = Productive), alpha = .1, size = 1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Productive), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE, size = 1) +
  ylab("Mean Unit Task performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") + 
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) + 
  scale_colour_manual(values = productivity.pal) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank())
  
```

***

#NN Task
###With individual prod points
```{r}
all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Next Number performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

##By productivity and count range
```{r}
all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID, count_range, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  geom_violin(aes(colour = Productive, fill = Productive), alpha = .1, size = 1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Productive), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE, size = 1) +
  ylab("Mean Next Number performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") + 
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) + 
  scale_colour_manual(values = productivity.pal) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank())
```

***

#Math Facts
##With individual prod points
```{r}
all.data %>%
  filter(Task == "MF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Math Facts performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

##By productivity and count range
```{r}
all.data %>%
  filter(Task == "MF")%>%
  group_by(SID, count_range, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  geom_violin(aes(colour = Productive, fill = Productive), alpha = .1, size = 1, 
              show.legend = FALSE)  + 
  geom_point(position=position_jitterdodge(jitter.width = .3, 
                                           jitter.height = .1, 
                                           dodge.width = .9),
             aes(colour = Productive, group=Productive), 
             size=1.5,
             alpha = .9,
               show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE, size = 1) +
  ylab("Mean Math Facts performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") + 
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal) + 
  scale_colour_manual(values = productivity.pal) +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank())
  
```

***

#Indefinite
##With individual prod points
NB, this does not include all participants.
```{r}
all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Productive, y = mean, fill=Productive)) +
  geom_violin(aes(fill = Productive, colour = Productive), alpha = .1, size = 1) +
  geom_point(aes(x = Productive, y = mean, colour = Productive),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
             alpha = .9,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1.5)+
  ylab("Mean Indefinite performance") + 
  xlab('') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = productivity.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide ="none")
```

***

#Unit, NN, and MF together
##With individual prod points
```{r}


#now for just kids at ceiling
tmp <- all.data %>%
  mutate(sf.quartile = cut(mean.unit, 
                                breaks=quantile(mean.unit, na.rm=TRUE), 
                                include.lowest=TRUE))%>%
  mutate(mf.ceiling = ifelse(mean.mf >= .75, ">= 75% correct", "< 75% correct"))


tmp %>%
    filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF", 
           sf.quartile == "(0.875,1]")%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit Task", "Next Number", "Math Facts")))%>%
  group_by(SID, Task)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Task, y = mean, fill=Task)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95),
                      geom="bar", alpha = .5, colour = "black") +
  # geom_violin(alpha = .5) +
  geom_point(aes(x = Task, y = mean, colour = Task),
               position=position_jitter(width = .18, height = .035),
               size=1.5,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1)+
  ylab("Mean task performance") + 
  xlab('Task') + 
  theme_bw(base_size = 13) + 
  theme(legend.position = "bottom") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank()) +
  ylim(0, 1.0) +
  scale_fill_manual(values = three.pal, guide = "none") +
  scale_colour_manual(values = three.pal, guide = "none")

ggsave("~/Documents/Projects/sf_math/Analysis/all_tasks_ceiling.png", width = 5.25, height = 4.5)
```

##By productivity and count range (this needs a little work)
```{r}
all.data %>%
  filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF")%>%
  group_by(SID, count_range, Task, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct)), na.rm=TRUE),
            sd = sd(as.numeric(as.character(Correct)), na.rm=TRUE)) %>%
ggplot(aes(x=count_range, y=mean, fill = Productive)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1, 
              show.legend = FALSE)  + 
  # geom_point(position=position_jitterdodge(jitter.width = .3, 
  #                                          jitter.height = .1, 
  #                                          dodge.width = .9),
  #            aes(colour = Productive, group=Productive), 
  #            size=1.5,
  #            alpha = .9,
  #              show.legend=TRUE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2, 
               show.legend = FALSE) +
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw(base_size = 10) + 
  theme(legend.position = "bottom") + 
  theme(text = element_text(size = 10)) +
  ylim(0, 1.0) +
  scale_fill_brewer(palette = "Dark2") + 
  # scale_colour_manual(values = productivity.pal) +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "bottom", 
        legend.title = element_blank()) + 
  facet_grid(~Task)
  
```

#Mean performance by item by task
```{r}
##For all tasks, by item
all.data %>%
  filter(Task == "MF" | 
         Task == "WCN" | 
           Task == "SF")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "6", "7", "15", "20", 
                                                  "21", "24", "26", "30", "32", 
                                                  "34", "46", "51", "57", "60", "62", "64", 
                                                  "71", "73", "81", "83", "84", "86",
                                                  "93", "95")), 
         Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit", 
                                                                       "Next Number", 
                                                                       "Math Facts")))%>%
  group_by(Productive, Task, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Productive, group = Productive)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  facet_grid(~Task, scale = "free_x") +
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  labs(x = "Number queried", y = "Mean performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
  
```


##Mean Unit task performance by HCNN
```{r}
all.data %>%
  filter(Task == "SF")%>%
  mutate(highest_contig = factor(highest_contig, levels = c("0", "1", "7", "24", "26", "30", 
                                                             "62", "71", "83", "95")))%>%
  group_by(highest_contig)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = highest_contig, y = mean, group= highest_contig)) +
  geom_point(size = 2) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw(base_size = 10) + 
  langcog::scale_color_solarized() +
  theme(legend.position = "bottom", 
        legend.title = element_blank()) +
  labs(x = "Highest contiguous NN", y = "Mean Unit Task performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

##Unit task by mean MF
```{r}
all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, mean.mf)%>%
  summarise(mean_unit = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = mean.mf, y = mean_unit)) +
  geom_point() + 
  geom_smooth(method = "lm") + 
  geom_jitter()
```


#Correlations
```{r}
sub.dat <- all.data %>%
  distinct(SID, Age, IHC, FHC, mean.unit, mean.mf, mean.nn, highest_contig, highest_num)%>%
  dplyr::select(-SID)%>%
  mutate(highest_contig = as.numeric(highest_contig))
  
library(corrplot)

M<-cor(sub.dat)
head(round(M,2))

#add p values
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(sub.dat)
head(p.mat[, 1:8])

corrplot(M, type="upper", order="hclust", method = "color",
         addCoef.col = "white",
         tl.col="black", tl.srt=45,
         p.mat = p.mat, sig.level = 0.01)

```

---



---








##Attempting to visualize these models  
```{r}
# library(dotwhisker)
#visualizing regressions
full.model <- summary(sf.large.plusmf)

AIC <- as.numeric(full.model$AICtab[1])

full.model.df <- data.frame(coef(full.model)[,0:4])
full.model.df <- add_rownames(full.model.df, "Parameter")

full.model.df %<>%
  mutate(Parameter = ifelse(Parameter == "highest_contig.c", "HCNN",
                            ifelse(Parameter == "fhc.c", "FHC",
                                   ifelse(Parameter == "count_rangeOutside", "Beyond IHC",
                                          ifelse(Parameter == "age.c", "Age", 
                                                 ifelse(Parameter == "mean.mf.c", "Math Facts", "Intercept"))))))%>%
  mutate(Parameter = factor(Parameter, levels = c("Age","Beyond IHC", "Math Facts", "FHC", "HCNN", "Intercept"), 
                             labels = c("Age", "Within Initial Count",
                                        "Math Facts",  "Final Highest Count", "Highest Contig. Next Number",
                                         "Intercept")))

full.model.df %>%
ggplot(aes(x = Parameter, y = Estimate)) +
  geom_pointrange(aes(ymin = Estimate - 1.96 * Std..Error,
                      ymax = Estimate + 1.96 * Std..Error,
                      colour = Parameter), size = .85) +
  geom_hline(yintercept = 0, color = "grey", linetype = "dashed") +
  theme_bw(base_size = 13.5) +
  theme(panel.grid = element_blank(), 
        legend.position = "none") +
  coord_flip() +
  langcog::scale_color_solarized() +
  xlab("") +
  scale_y_continuous(name = "Coefficient Estimate (log likelihood)")
ggsave("~/Documents/Projects/sf_math/Analysis/coefficients.png", width = 5.75, height = 3.25)
```



#Post-hoc: SF and MF comparison


##Mean performance in each task by Unit Task quartile (SF, MF, NN)
```{r}


```

#Accuracy by Task - collapsed across all counters
```{r}
model.tasks.df <- tmp %>%
  filter(Task == "SF" | 
           Task == "WCN" | 
           Task == "MF") %>%
   mutate(highest_contig = as.integer(highest_contig), 
          Task = factor(Task, levels = c("SF", "WCN", "MF")),
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         # highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))

#LOOK AT JUST CEILING
#base model 
model.tasks.base <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial",
                         data = subset(model.tasks.df, sf.quartile == "(0.875,1]"))

#does performance significant differ by task? 
model.tasks.1 <- glmer(Correct ~ Task + count_range + age.c + (1|SID), family = "binomial", 
                      data = subset(model.tasks.df, sf.quartile == "(0.875,1]"))

#compare
anova(model.tasks.base, model.tasks.1, test= 'LRT') #yes, tasks adds

summary(model.tasks.1)

#Now look at all kids
  #base model 
  model.tasks.base.all <- glmer(Correct ~ count_range + age.c + (1|SID), family = "binomial",
                           data = model.tasks.df)
  
  #does performance significant differ by task? 
  model.tasks.1.all <- glmer(Correct ~ Task + count_range + age.c + (1|SID), family = "binomial", 
                        data = model.tasks.df)
  
  #compare
  anova(model.tasks.base.all, model.tasks.1.all, test= 'LRT') #yes, tasks adds
  
  summary(model.tasks.1.all)

```

##For top quartile, t-test of mean MF and SF performance
```{r}
#for top quantile, t-test of mf and sf performance
ms <- tmp %>%
  group_by(SID, sf.quartile, Task)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  filter(sf.quartile == '(0.875,1]')

t.test(subset(ms, sf.quartile == '(0.875,1]' & Task == "MF")$mean, 
       subset(ms, sf.quartile == '(0.875,1]' & Task == "SF")$mean, var.equal = TRUE)
```

##T-test between mean SF and NN performance for top quartile
```{r}
#what about for next number?
ms <- tmp %>%
  group_by(SID, sf.quartile, Task)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  filter(sf.quartile == '(0.875,1]')

t.test(subset(ms, sf.quartile == '(0.875,1]' & Task == "WCN")$mean, 
       subset(ms, sf.quartile == '(0.875,1]' & Task == "SF")$mean, var.equal = TRUE)
```

##Exploratory - does mean indefinite performance predict SF? 
```{r}

task.pal2 <- c("#2aa198")
               
indef.model <- model.df %>%
  filter(!is.na(mean.indef.c))

indef.base <- glmer(Correct ~ mean.mf.c + highest_contig.c + count_range + age.c + (1|SID), 
                    family = "binomial", data = indef.model)

indef.indef <- glmer(Correct ~ mean.indef.c + mean.mf.c + highest_contig.c + count_range + age.c + (1|SID), 
                     family = "binomial", data = indef.model)

#compare
anova(indef.base, indef.indef, test = 'LRT')

summary(indef.indef)

##visualize
indef.model %>%
  group_by(SID, mean.indef)%>%
  summarise(mean.sf = mean(Correct, na.rm = TRUE))%>%
  ggplot(aes(x = mean.indef, y = mean.sf)) + 
  geom_point(position = position_jitter(width = .01, height = .01)) + 
  geom_smooth() +
  theme_bw()

#making the graph I want
tmp.df <- all.data %>%
  dplyr::select(SID, Age, Task, Correct)%>%
  filter(Task == "SF" | 
           Task == "MF" | 
           Task == "WCN")%>%
  group_by(SID, Task)%>%
  summarise(Mean = mean(Correct, na.rm = TRUE))

mean.indef <- all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID)%>%
  summarise(mean.indef = mean(Correct))

ms.tmp <- right_join(tmp.df, mean.indef, by = "SID")

all.data %>%
  filter(!is.na(mean.indef))%>%
  filter(Task == "SF")%>%
  mutate(indef.bin = ifelse((mean.indef <.25 & mean.indef <= .5), "0% — 50%", "50% — 100"))%>%
  group_by(SID, Task, indef.bin)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = indef.bin, y = mean, fill=Task)) +
  geom_violin(aes(fill = Task), alpha = .4) + 
  geom_point(aes(x = indef.bin, y = mean, colour = Task),
               position=position_jitter(width=0.15,height=0.02),
               size=1.5,
               show.legend=TRUE, 
             inherit.aes = FALSE) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.1, size = 1)+
  ylab("Mean Unit Task performance") + 
  xlab('Mean Indefinite Next Number performance') + 
  theme_bw(base_size = 15) + 
  theme(legend.position = "right") +
  theme(panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.position = "none") +
  ylim(0, 1.0) +
  scale_fill_manual(values = "#091E5B") + 
  scale_color_manual(values = "#091E5B") + 
  coord_fixed(ratio = 1.8)

ggsave("~/Documents/Projects/sf_math/Analysis/indef.png")
```

##Post-hoc: Predicting mean performance by task, controlling for age and starting number
For children who are at ceiling in SF task, is there evidence that they draw upon one source of information more strongly than the other? If they generalize the SF from '+1' operation and from productive counting knowledge, then for children at ceiling there should no difference between these two tasks. If children weight one source of information more strongly, however, we should find a significant effect of task when controlling for starting number and age.
```{r}
ms1 <- tmp %>%
  filter(sf.quartile == "(0.875,1]", 
         Task=="MF" | 
           Task == "WCN")%>%
  mutate(starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))

summary(lmer(Correct ~ Task + starting_num.c + Age + (1|SID), 
              data = ms1))
```


```{r, include = FALSE}
indef.model <- model.df %>%
  filter(!is.na(mean.indef))

sf.indef.base <- glmer(Correct ~ count_range + age.c + (1|SID), 
                       family = "binomial", data = indef.model)
sf.indef <- glmer(Correct ~ mean.indef + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)

#test
anova(sf.indef.base, sf.indef, test = 'LRT')

#what about FHC and HCNN
sf.indef.fhc <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.base, sf.indef.fhc, test = 'LRT')

sf.indef.highest_contig <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.base, sf.indef.highest_contig, test = 'LRT')

#does HCNN add to this - yes
sf.indef.highest_contig.indef <- glmer(Correct ~ mean.indef + highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.highest_contig, sf.indef.highest_contig.indef, test = 'LRT')

#does fhc add to this
sf.indef.highest_contig.indef.fhc <- glmer(Correct ~ fhc.c + mean.indef + highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.highest_contig.indef, sf.indef.highest_contig.indef.fhc, test = 'LRT') #yes

#what about the addition of math facts
#individual model
sf.indef.mf <- glmer(Correct ~ mean.mf + count_range + age.c + (1|SID), 
                     family = "binomial", data = indef.model)
anova(sf.indef.base, sf.indef.mf, test = 'LRT')

#add to large model
sf.indef.highest_contig.indef.fhc.mf <- glmer(Correct ~ mean.mf + fhc.c + mean.indef + highest_contig.c + count_range + age.c + (1|SID), 
                  family = "binomial", data = indef.model)
anova(sf.indef.highest_contig.indef.fhc, sf.indef.highest_contig.indef.fhc.mf, test = 'LRT')
```





```{r, include = FALSE}
# task.df <- all.data %>%
#   filter(Task == "SF" |
#            Task == "WCN" | 
#            Task == "MF")%>%
#   mutate(Task_item = as.integer(as.character(Task_item)), 
#          age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), 
#          task_item.c = as.vector(scale(Task_item, center = TRUE, scale=TRUE)))
# 
# task.model <- glmer(Correct ~ Task*novel_same + age.c + (1|SID), 
#                     family = "binomial", data = task.df)
# summary(task.model)
```


```{r, include = FALSE}
# #Exploratory model: Predicting probability from highest count 
# #Can you predict whether someone will be productive or nonproductive based on t5%heir initial highest count?
#   
# model.df %<>%
#   mutate(productive.log = ifelse(productive == "productive", 1, 0))
# 
# model.prod <- model.df %>%
#   distinct(SID, age, productive.log, initial_highest, final_highest)
# 
# model.prod.prob <- glr(productive.log ~ initial_highest + age + (1|SID), 
#                     family = "binomial", data = model.prod)
# model.prod.prob.base <- glmer(productive.log ~ age + (1|SID), 
#                     family = "binomial", data = model.prod)
# with(model.prod.prob@optinfo$derivs,max(abs(solve(Hessian,gradient)))<2e-3)
# anova(model.prod.prob, model.prod.prob.base, test = 'LRT')
```
