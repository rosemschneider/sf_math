---
title: "Sources of knowledge in children's acquisition of the successor function"
bibliography: citations.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf } \\  \\  \\ }

abstract: 
    "Through understanding the successor function, i.e. for any natural number n, its successor is n+1, we can gain the insight that the natural numbers are infinite. Recent work has suggested acquisition of this logical property is more protracted than previously thought, with a fully generalized understanding of the successor function not apparent until 5.5 to 6 years of age. While such work links successor knowledge with counting mastery, the exact processes underlying this developmental transition remain unknown. Here, we examined two hypothesized mechanisms: (1) productive counting knowledge, or mastery of the recursive process through which number words are generated, and (2) formally trained arithmetic, specifically the ‘+1’ operation. We tested the relationship between successor knowledge, productive counting, and arithmetic proficiency in 140 3.5 to 6 year-olds. We found that while both productive counting and arithmetic mastery predicted successor knowledge, mean arithmetic performance was significantly lower for all children, even those at ceiling in implementing the successor function This surprising dissociation suggests children do not draw upon the ‘+1’ operation in acquiring the successor function. Rather, these findings are more consistent with the hypothesis that this knowledge is acquired through productive counting, and the recognition that numbers are recursively generated through an implementation of the successor function."
    
keywords:
    "Number; language; cognitive development"
    
output: cogsci2016::cogsci_paper 
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)
```

```{r, libraries}
library(png)
library(grid)
library(ggplot2)
library(xtable)
require("knitr")
# opts_knit$set(root.dir = "~/Documents/Projects/sf_math/") #this is specific to RMS, change accordingly
library(tidyverse)
library(magrittr)
library(langcog)
library(lme4)
library(stringr)
library(RColorBrewer)
library(ggthemes)

'%!in%' <- function(x,y)!('%in%'(x,y))
```

# Introduction 

One of the most fundamental challenges in learning is extracting a set limitlessly productive rules from limited experiences. While humans are remarkably adept learners across a multitude of domains, a powerful application of this prodigious capacity is in the acquisition of symbolic number. Although linguistic number input and expression are decidedly finite, nevertheless we know the natural numbers to be *infinite*; we recognize that for every number, its successor can be obtained by simply adding '1,' and even intuitively know that *bajillion-two* follows *bajillion-one*, even though neither words indicate natural numbers. How does such an understanding arise, and what are the causal mechanisms underlying young learners' ability to acquire such an infinitely productive rule from their extremely finite early number input? In the present study, we test two hypothesized sources of knowledge in children's acquisition of the successor function, a logical property of number which states that for every natural number *n*, its successor is defined as *n*+1.

That such an infinitely generative function should exist is far from obvious in both early linguistic number input [@rule2015; @willits2016], as well as children's earliest expressions of number [@fuson1988]. Children's early exposure to the count list is extremely limited, and although most US children are able to recite a portion of the count list by the age of two, it is treated similarly to the "*ABCs.*" That is, children at this age treat the count list as an "unbreakable chain" which must be recited in its entirety, and which lacks any recursive structure. From the ages of about 2 to 3.5 years, children seem to learn the count list independently of the meanings of number words; although most children have learned the meanings of *one*, *two*, and *three* by about 3.5 years, they do not yet understand the connection between counting and the cardinal meanings of number words [@wynn1990; @wynn1992]. With the acquisition of *four*, however, children's understanding of cardinality and counting seem to finally come into alignment, in that they suddenly seem to understand how the last word said while counting a set indicates the cardinality of that set. 

On some accounts, [@carey2004; @carey2009], children's acquisition of this *Cardinal Principle* (CP, @gelman1978) is accomplished by an analogical mapping: children notice that both the count list and the cardinalities it represents both differ by exactly *one*, leading them to hypothesize that this may hold true for other numbers as well. Critically, such an account of CP-acqusition implicates the successor function, in that children realize that any number's successor is exactly *one* greater than the current number.

@sarnecka2008 provided support for such an account of CP-acquisition using a paradigm called the 'Unit Task.' In this task, children are told a set of *N* objects are in a box, and then observe the addition of 1 item, with the critical question "Are there *N*+1 or *N*+2 in the box now?" To correctly answer this question, children must understand that the addition of one item to an established cardinality necessitates moving up one spot in the count list. Consistent with the hypothesis that children acquire the CP through an induction of the successor function, Sarnecka \& Carey found that CP-knowers exhibited significantly greater Unit Task performance in comparison to subset-knowers (children who have not yet acquired the CP). 

Subsequent work has found that, while CP-knowers demonstrate some understanding of the successor function on the Unit Task, such knowledge seems only to be available for numbers to which the child can accurately count. @davidson2012 and @cheung2017 classified CP-knowers according to their counting proficiency, and found that only the most competent counters were able to successfully implement the successor function for all numbers within their count range. In contrast, less able counters performed at chance on the Unit Task, even for numbers to which they were able to count. In conjunction with other recent work which shows a gap between CP knowledge and generalized successor knowledge [@spaepen2018], these results indicate that acquiring the successor function occurs significantly after learning the CP, perhaps by several years [@cheung2017]. 

In the intervening years between learning the CP and acquiring the successor function (between the ages of about 4 and 6), children encounter increasing numerical input and experiences. They continue to master the count routine, and at some point are able to extract recursive counting rules which enable them to count increasingly high. At the same time, children begin formal education, and are trained on arithmetic facts such as *5+1=6,* *6+1=7*, and so on. 

@cheung2017 proposed that children may leverage such new and developing numerical knowledge in acquiring the successor function. Specifically, Cheung and colleagues present both recursive counting knowledge and trained "math facts" mastery as possible paths to successor knowledge. On the first alternative, which we will refer to as "Productive Counting," as children master the recursive base-structure of number, they notice that the next number in the base is generated through implementing the successor function. Thus, such an account would predict that children who demonstrate Productive Counting knowledge should be more likely to exhibit generalized successor knowledge. The second alternative, which we will refer to as "Math Facts," hypothesizes that the successor function is not inferred, but trained; as children learn arithmetic operations such as *4+1=5,* they may hypothesize that this trained "+1" operation holds for *any* number. Therefore, the "Math Facts" hypothesis predicts that children's successor knowledge should be significantly predicted by their mastery of the "+1" operation. Importantly, this hypothesis also predicts that children at ceiling on the successor task should be similarly at ceiling in solving addition problems with "+1."

In the present work, we tested these two hypothesized causal mechanisms in successor function acquisition. <Brief precis of methods>. <Tested whether children draw upon these hypothesized sources of knowledge in blah blah blah>

```{r setup}
#load data
data.raw <- read.csv("~/Documents/Projects/sf_math/Data/sf_math_data.csv")%>%
  filter(SID != "CopyPasteMe", 
         SID != "?")%>%
  droplevels()%>%
  filter(Correct != "HELP")%>% #temporary while we resolve helps
  mutate(Age = as.numeric(as.character(Age)),
         Correct = as.integer(as.character(Correct)))%>%
  mutate(Age = round(Age, 2), 
         Agegroup = cut(Age, breaks = c(3.49, 4, 4.5, 5, 5.5, 6), 
                        labels = c("3.5-4", "4-4.5", "4.5-5", 
                                   "5-5.5", "5.5-6")))%>% #add agegroups
  dplyr::select(-Response_single, -Response_double)%>% #remove double coding
  dplyr::rename(Response = Response_final) #rename for code

hc.df <- read.csv("~/Documents/Projects/sf_math/Data/sf_math_hc.csv")%>%
  dplyr::select(-IHC_single, - FHC_single, -Special_count, -Notes, -RMS.note)%>%
  filter(Exclude_trial != 1, 
         IHC_final != "HELP", 
         FHC_final != "HELP")%>%
  dplyr::rename(FHC = FHC_final, 
                IHC = IHC_final)%>%
  filter(!is.na(FHC), 
         !is.na(IHC))%>%
  mutate(IHC = ifelse(as.integer(as.character(IHC)) > 120, 120, as.integer(as.character(IHC))), 
         FHC = ifelse(as.integer(as.character(FHC)) > 120, 120, as.integer(as.character(FHC)))) #add cap to IHC and FHC
```

```{r productive, warning = FALSE}
#classify children as productive or nonproductive
hc <- hc.df %>% 
  dplyr::select(SID, Last_successful, IHC, FHC) %>%
  mutate_at(c('Last_successful','IHC','FHC'),
            function(col) as.integer(str_replace_all(col,'\\D',''))) %>% 
  mutate(Last_successful = ifelse(is.na(Last_successful), 120, Last_successful))%>%
  mutate(SID = as.character(SID))
# 
# 
is.productive = function(subject){
  # takes as input the data for a single subject
  # RULES:
  # - counts to 120 unaided = productive
  # - after making first error, counts >= 20 higher, with no more than 3 errors on way
  if(subject$IHC[1] >= 120){
    # if they get to 120 on first try, = productive
    return("Productive")
  } else if(subject$FHC[1] == 120 & nrow(subject) < 4) {
    return("Productive")
  } else if(subject$FHC[1] < 120 & nrow(subject) == 1 
            & subject$FHC[1] == subject$IHC[1]) {
    return("Nonproductive")
  } else if((subject$FHC[1] - subject$IHC[1]) >= 20){
    # if their final is >= 20 larger than their intial...
    if(nrow(subject) < 4){
      # and they've made 3 or fewer total errors, = productive
      return("Productive")
    } 
    else {
      for(i in 1:nrow(subject)){ # start at row 2
        # check if they ever made it >= 20 counts & <= 3 errors after an error
        runLength = 0 # they just made an error, so no post-error successes yet
        numErrors = 0 # first row was an error if it's not finalCount == 120
        prev = subject$Last_successful[i]
        for (j in i+1:nrow(subject)){ # from current row until end...
          numErrors = numErrors + 1 # new row means new error
          runLength = runLength + (subject$Last_successful[j] - prev)
          # ^ add difference between current count and last count to run length
          prev = subject$Last_successful[j] # update last count
          if(runLength >= 20 & numErrors < 4){
            # if at any point the productivity conditions are met...
            return("Productive") # = productive
          }
        }
      }
      # productivity conditions were never met (because we got to this point) so...
      return("Nonproductive") # != productive
    }
  } else {
    # highest is not >= 20 greater than initial
    return("Nonproductive")
  }
}

# 
#make function to run for all participants
unique_SIDs <- as.vector(unique(hc.df$SID))
# 
class_prod <- function(vector) {
  temp_data <- data.frame()
  for (i in vector) {
    prod.class <- data.frame(i, is.productive(subset(hc, SID == i)))
    # print(i) # for debugging
    names(prod.class) <- c("SID", "productive")
    prod.class %<>%
      mutate(SID = as.character(SID), 
             productive = as.character(productive))
    temp_data <- bind_rows(temp_data, prod.class)
  }
  return(temp_data)
}
# 

#get productive classification for every participant
productive <- class_prod(unique_SIDs)%>%
  dplyr::rename(Productive = productive)

#remove last-successful from hc so you can add IHC and FHC to data.raw
hc %<>%
  dplyr::select(-Last_successful)

#add productive classifications
productive <- full_join(productive, hc, by = "SID")%>%
  distinct(SID, IHC, FHC, Productive)

#full join with raw data
data.raw <- full_join(data.raw, productive, by = "SID") 

#made SID and Productive factors again #MSaPFA
data.raw %<>%
  mutate(SID = factor(SID), 
         Productive = factor(Productive))
```

```{r knower_level}
cp.df <- data.raw %>%
  filter(Task == "GiveN")%>%
  group_by(SID)%>%
  summarise(sum_correct = sum(Correct, na.rm = TRUE))%>%
  mutate(Knower.level = ifelse(sum_correct >= 4, "CP-knower", "Subset-knower"))%>%
  dplyr::select(-sum_correct)

data.raw <- full_join(data.raw, cp.df, by = "SID")
```

```{r hcnn, warning = FALSE}
#Get kids who failed NN for highest contiguous
failed.nn <- data.raw %>%
  filter(Task == "WCN", 
         Correct == 0, 
         Trial_number == "Training")

failed.nn.sids <- unique(as.vector(failed.nn$SID))

#get unique ids
unique.nn <- data.raw %>%
  filter(Task == "WCN")%>%
  distinct(SID)

unique.nn <- as.vector(unique.nn$SID)
nextnums <- as.vector(c(7, 26, 30, 62, 83, 95, 71, 24))

#this is a function that pulls out the largest number for which a participant had a correct consecutive
get_contiguous <- function(){
  contig <- data.frame()
  for (sub in unique.nn) {
    tmp <- data.raw %>%
      filter(Task == "WCN",
             SID == sub, 
             Correct == 0)%>%
      mutate(Task_item= as.integer(as.character(Task_item)))%>%
      mutate(Task_item = sort(as.integer(as.character(Task_item))))
    if (length(tmp$SID) == 0) {
      highest_contig = 95
      sub_contig <- data.frame(sub, highest_contig) 
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else if (sub %in% failed.nn.sids) {
      highest_contig = 0
      sub_contig <- data.frame(sub, highest_contig) 
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else if (length(tmp$Task_item) > 0 & min(as.integer(as.character(tmp$Task_item))) == 7) {
      highest_contig = 1
      sub_contig <- data.frame(sub, highest_contig)
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    } else {
      min.nn <- min(as.integer(as.character(tmp$Task_item)))
      prev_correct <- nextnums[nextnums < min.nn]
      highest_contig <- max(prev_correct)
    
      sub_contig <- data.frame(sub,
                             highest_contig) 
      sub_contig %<>%
        mutate(sub = as.character(sub),
                highest_contig = as.character(highest_contig))
      contig <- bind_rows(contig, sub_contig)
    }
  }
  contig %<>%
    mutate(highest_contig = as.character(highest_contig))
  return(contig)
}

highest_contiguous_nn <- get_contiguous()%>%
  dplyr::rename(SID = sub)

#add this to df 
data.raw <- full_join(data.raw, highest_contiguous_nn, by = "SID")

# #how many kids don't have a highest contiguous NN? 
# all.data %>%
#   filter(is.na(Language))
#   filter(is.na(highest_contig))%>%
#   distinct(Language, SID)%>%
#   group_by(Language)%>%
#   summarise(n = n())%>%
#   kable()

#Check - does anyone have NA for HCNN? 
# data.raw %>%
#   filter(is.na(highest_contig))%>%
#   filter(Exclude_analysis == 0)
```

```{r global_exclusions}
#how many kids pre exclusions, minus kids excluded for not being CP knowers
pre.excl <- data.raw %>%
  filter(Exclude_analysis == 1)%>%
  distinct(SID, Exclude_analysis_reason)%>%
  group_by(Exclude_analysis_reason)%>%
  summarise(n = n())

#exclude these kids from analysis
all.data <- data.raw %>%
  filter(Exclude_analysis != 1)
```

```{r task_exclusions}
# #how many kids are excluded from which tasks
# all.data %>%
#   filter(Exclude_task == 1)%>%
#   distinct(SID, Exclude_task, Excluded_task, Exclude_task_reason)

#exclude
all.data %<>%
  filter(Exclude_task != 1)
```

```{r trial_exclude}
# #how many trials excluded, and for what reason
# all.data %>%
#   filter(Exclude_trial == 1)%>%
#   group_by(Task, Exclude_trial_reason)%>%
#   summarise(n = n())%>%
#   kable()

#exclude these trials
all.data %<>%
  filter(Exclude_trial != 1)
```

```{r training_exclude}
# #how many kids failed training
# all.data %>%
#   filter(Trial_number == "Training", 
#          Correct == 0)%>%
#   group_by(Task)%>%
#   summarise(n = n()) %>%
#   kable()

#filter out training trials 
all.data %<>%
  filter(Trial_number != "Training")

# #how many trials do we have for each task?
# all.data %>%
#   filter(Task == "SF" | 
#          Task == "WCN" |
#            Task == "MF")%>%
#   group_by(Task)%>%
#   summarise(n = n()) %>%
#   kable()
```

```{r within_outside}
#classify trials as within or outside count range
all.data %<>%
  mutate(count_range = ifelse((Task == "SF" | Task == "WCN" | Task == "MF") & as.numeric(as.character(Task_item)) <= IHC, "Within", "Outside")) %>%
  mutate(count_range = factor(count_range, levels = c("Within", "Outside")))
```

```{r hnn}
#highest next number
#Create a lookup table with the highest NN correctly answered
lookup <- all.data %>%
  filter(Task == "WCN")%>%
  filter(Correct == 1)%>%
  group_by(SID)%>%
  summarise(max = max(as.integer(as.character(Task_item))))

no.corr.nn <- all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID)%>%
  summarise(mean = mean(Correct, na.rm = TRUE))%>%
  filter(mean == 0)

no.corr.nn.sids <- as.vector(unique(no.corr.nn$SID))

#Function that adds the highest NN to a participant's row in the SF dataframe
add_highest_num <- function(df) {
  tmp <- df
  for (row in 1:nrow(tmp)) {
    sub = as.character(tmp[row, "SID"])
    if (sub %in% no.corr.nn.sids) {
      highest_num = 0
      tmp[row, "highest_num"] = highest_num
    } else {
      highest_num = subset(lookup, SID == sub)$max
      tmp[row, "highest_num"] = highest_num
    }
  }
  return(tmp)
}

#run this function on SF dataframe
all.data <- add_highest_num(all.data)
```

```{r prod.gradient}
all.data %<>%
  mutate(delta.hc = FHC-IHC, 
         prod.gradient = delta.hc/(120-IHC), 
         prod.gradient = ifelse(IHC == 120 | IHC == 119, 1, as.numeric(prod.gradient)))
```

```{r mean_indef}
indef.mean <- all.data %>%
  filter(Task == "Indefinite")%>%
  group_by(SID)%>%
  summarise(mean.indef = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, indef.mean, by = "SID")
```

```{r mean_three}
mf.sum <- all.data %>%
  filter(Task == "MF")%>%
  group_by(SID)%>%
  summarise(mean.mf = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, mf.sum, by = "SID")

sf.mean <- all.data %>%
  filter(Task == "SF")%>%
  group_by(SID)%>%
  summarise(mean.unit = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, sf.mean, by = "SID")

nn.mean <- all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID)%>%
  summarise(mean.nn = mean(Correct, na.rm = TRUE))

all.data <- full_join(all.data, nn.mean, by = "SID")
```

# Method

##Participants
```{r demographics}
n.participants <- all.data %>%
  distinct(SID, Age)%>%
  summarise(n = n(),
            mean_age = round(mean(Age), 2), 
            sd_age = round(sd(Age), 2))

n.sex <- all.data %>%
  distinct(SID, Sex)%>%
  filter(Sex == "F")%>%
  group_by(Sex)%>%
  summarise(n = n())
```
We recruited `r n.participants$n` children between the ages of 3;6 and 5;11 (\emph{M} = `r n.participants$mean_age`, \emph{SD} = `r n.participants$sd_age`, \emph{N} female = `r n.sex$n`). XX children were excluded prior to testing in our abbreviated Give-N screening. An additional XX children were excluded due to failure to complete the Highest Count task, leaving a total of XX participants out of a planned sample of 150. 

##Procedure
Participants completed 5 tasks (Give-N, Highest Count with Prompts, Unit Task, Next Number, and Math Facts) in a fixed order. 

*Give-N*. Only children who had acquired the Cardinal Principle (CP) were included in this study. The experimenter presented children with a set of 10 plastic apples, bears, or bananas, and a plastic plate. Children were asked to place 6, 9, 7, or 5 objects (in that order) on the plate. After the child finished placing items in the plate, the experimenter asked ``Is that *N*? Can you please count it and check?'' If a child said that the number given was not the number requested, they were given the opportunity to fix the set. Children needed to correctly generate sets for all four requested quantities to be considered a CP-knower.

*Highest Count with Prompts.* This task assessed children's rote and productive counting knowledge. The experimenter introduced the game by saying, "This is a counting game. In this game, I want to you count as high as you can. Go ahead!" If a child made a mistake, or forgot the next number in the count list, the experimenter asked "What comes after *N*?" If the child was unable to correct their mistake, or still did not know the next number, the experimenter provided a prompt, saying "Actually, what comes after *N* is *N*+1. Can you keep counting?" Children were given a maximum of 12 such prompts; the maximum count in this task was 120, meaning that even children who required a prompt at every decade transition would be able to reach the highest number. 

If a child was unable to continue after receiving a prompt, or made an error, the task was ended. Children received a maximum of 3 prompts within a single decade, and could not make more than 3 consecutive errors (i.e., prompted counts separated by only one unprompted number).

*Unit Task*. This task was adapted from [@sarnecka2008]. 

# Results

Our primary question in this work is whether children's acquisition of the successor function is motivated by recursive counting knowledge, or mastery of trained arithmetic operations. First, we explore children's counting behavior, and describe differences between children classified as Productive and Nonproductive counters. Next, we construct several models to test whether Unit Task performance is best predicted by (1) Productivity; (2) IHC; (3) FHC; (4) Highest Contiguous Next Number\footnote{Although we initially preregistered simply the highest next number reached as a measure of productivity, we later adapted this measure to account for accuracy. We redefined this measure prior to collection and analysis of the complete dataset.}; or (5) mean "Math Facts" performance. Finally, we investigate differences in mean performance between Unit, Next Number, and "Math Facts" tasks. (Need to define each of these measures.) (explain why we have so many productivity predictors).

##Highest Count

```{r hc desc}
productivity.pal <- c("#666666","#00b8e6")

hc.table <- all.data %>%
  distinct(SID, Age, Productive, IHC, FHC)%>%
  group_by(Productive)%>%
  summarise(n = n(),
            m_ihc = round(mean(IHC)), 
            sd_ihc = round(sd(IHC), 2), 
            median_ihc = round(median(IHC)), 
            m_fhc = round(mean(FHC)), 
            sd_fhc = round(sd(FHC), 2), 
            median_fhc = round(median(FHC)))

error.freq <- full_join(hc.df, productive, by = "SID")%>%
  filter(!is.na(Last_successful))%>%
  filter(Last_successful != 120)%>%
  mutate(Error_type = ifelse(Last_successful %% 10 == 9 , "Decade end", 
                             ifelse(Last_successful %% 10 == 0, "Decade beginning", "Mid-decade")))

#mean number of prompts by Productivity
mean.error <- error.freq %>%
  filter(Last_successful != 120)%>%
  group_by(SID, Productive)%>%
  summarise(n = n())%>%
  group_by(Productive)%>%
  summarise(mean_prompts = round(mean(n, na.rm = TRUE), 2),
            sd_prompts = round(sd(n, na.rm = TRUE), 2))

#predicting IHC from Productivity 
ihc.fhc.test <- all.data %>%
  distinct(SID, Productive, IHC, FHC)

ihc.ttest <- t.test(subset(ihc.fhc.test, Productive == "Productive")$IHC, subset(ihc.fhc.test, Productive == "Nonproductive")$IHC, 
       var.equal = TRUE)


#what kinds of errors?
mean_prompts.type <- error.freq %>%
  group_by(Productive, Error_type)%>%
  summarise(n = n())%>%
  group_by(Productive)%>%
  mutate(total.n = sum(n), 
            prop = n/total.n)


# tab1 <- xtable::xtable(hc.table, 
#                       caption = "This table prints across one column.")
# 
# print(tab1, type="latex", comment = F, table.placement = "H")
```

Using our Productivity classification, we identified 73 children as Productive counters, and the remaining 71 as Nonproductive counters. A summary of Initial and Final Highest Counts by Productivity is shown in Table \ref{tab:hc}. Productive counters had significantly higher IHCs (*t*(`r ihc.ttest$parameter`) = `r round(ihc.ttest$statistic, 2)`, *p* = .0003) than Nonproductive counters, indicating a higher overall level of counting mastery. Critically, Productive counters used more prompts than Nonproductive counters (an average of `r mean.error$mean_prompts[2]` v. `r mean.error$mean_prompts[1]`) to reach a higher FHC. Thus, although children received a prompt at every error, only Productive counters were able to leverage their knowledge of the base-system in order to continue counting.

\begin{table}[t]
\centering
\begin{tabular}{c c c c } 
 \hline
 Productivity & N & Mean IHC (SD) & Mean FHC (SD) \\
 \hline
 Productive & `r hc.table$n[2]` & `r hc.table$m_ihc[2]` (`r hc.table$sd_ihc[2]`) & `r hc.table$m_fhc[2]` (`r hc.table$sd_fhc[2]`)  \\
 Nonproductive & `r hc.table$n[1]` & `r hc.table$m_ihc[1]` (`r hc.table$sd_ihc[1]`) & `r hc.table$m_fhc[1]` (`r hc.table$sd_fhc[1]`) \\ 
 \hline
\end{tabular}
\caption{Highest Count performance by Productivity classification.}
\label{tab:hc}
\end{table}

Additionally, Productive counters made a higher proportion of their errors at decade-transitions (`r round(mean_prompts.type$prop[5], 2)`) than either mid-decade (`r round(mean_prompts.type$prop[6], 2)`) or at the beginning of a decade (`r round(mean_prompts.type$prop[4], 2)`), indicating that their counting difficulties stemmed from memorizing decade labels, rather than from the base-system. In contrast, Nonproductive counters made errors roughly equally at both decade transitions (`r round(mean_prompts.type$prop[2], 2)`) and mid-decade (`r round(mean_prompts.type$prop[3], 2)`). 

```{r initial_final, fig.pos = "t", fig.width=3.2, fig.height=3.2, fig.cap = "Scatterplot of Initial and Final Highest Counts by Productivity classification. Points are jittered slightly to avoid overplotting."}
initial_final <- all.data %>%
  filter(!is.na(Productive))%>%
  distinct(SID, IHC, FHC, Productive, prod.gradient)%>%
  mutate(IHC = as.numeric(IHC), 
         FHC = as.numeric(FHC))

initial_final %>%
ggplot(aes(x = IHC, y = FHC, 
                          color = Productive)) +
  geom_point(size = .25) + geom_jitter(width = .1) +
  labs(x = "Initial highest count", y = "Final highest count", 
                      color = "", title = "") +
  scale_x_continuous(breaks = seq(0, 140, 10)) + 
  scale_y_continuous(breaks = seq(0, 140, 10)) + 
  theme_bw() +
  theme(panel.grid.minor = element_blank(), 
        legend.position = "bottom", 
        legend.text = element_text(size = 6), 
        axis.text = element_text(size = 6), 
        axis.title = element_text(size = 7)) +
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

##Accuracy by task

```{r 3_tasks, fig.pos = "t", fig.width=3.5, fig.height=2.5, fig.cap = "Mean performance for Unit, Next Number, and Math Facts tasks by Productivity. Bars represent mean performance, with error bars indicating mean standard error. Violin plots indicate density distribution of responses."}
three.pal <- c("#7570B3", "#E7298A", "#66A61E")

all.data %>%
  filter(Task == "SF" |
           Task == "WCN" |
           Task == "MF")%>%
  mutate(Task = factor(Task, levels = c("SF", "WCN", "MF"), 
                       labels = c("Unit", "Next Number", "Math Facts"))) %>% 
  group_by(SID, Task, Productive)%>%
  summarise(mean = mean(as.numeric(as.character(Correct), na.rm=TRUE)),
            sd = sd(as.numeric(as.character(Correct), na.rm=TRUE))) %>%
  ggplot(aes(x = Task, y = mean, fill=Task)) +
  stat_summary(fun.y = mean, position = position_dodge(width = .95), 
                      geom="bar", alpha = .5, colour = "black") +
  geom_violin(alpha = .1) +
  stat_summary(fun.data = mean_se, geom="errorbar", 
               position = position_dodge(width=0.90), width = 0.2)+
  ylab("Mean correct") + 
  xlab('') + 
  theme_bw() + 
  theme(legend.position = "bottom") +
  theme(text = element_text(size = 12), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(), 
        legend.title = element_blank(),  
        axis.text = element_text(size = 6), 
        axis.title = element_text(size = 7), 
        strip.text.x = element_text(size = 6)) +
  ylim(0, 1.0) +
  scale_fill_manual(values = three.pal, guide = "none") +
  scale_colour_manual(values = productivity.pal, guide = "none") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  facet_grid(~Productive)

##predicting accuracy by task and productivity - t-tests
#Unit task 
unit.t <- all.data %>%
  filter(Task == "SF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

unit.test <- t.test(subset(unit.t, Productive == "Productive")$mean, 
       subset(unit.t, Productive == "Nonproductive")$mean, var.equal = TRUE)

nn.t <- all.data %>%
  filter(Task == "WCN")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

nn.test <- t.test(subset(nn.t, Productive == "Productive")$mean, 
       subset(nn.t, Productive == "Nonproductive")$mean, var.equal = TRUE)

mf.t <- all.data %>%
  filter(Task == "MF")%>%
  group_by(SID, Productive)%>%
  summarise(mean = mean(Correct))

mf.test <- t.test(subset(mf.t, Productive == "Productive")$mean, 
       subset(mf.t, Productive == "Nonproductive")$mean, var.equal = TRUE)

#Is mean performance significantly lower by task for MF for NN by productivity? 
simple.model <- all.data %>%
  filter(Task == "SF" | 
           Task == "WCN" | 
           Task == "MF")%>%
  group_by(SID, Task, Age, Productive)%>%
  summarise(mean = mean(Correct))

lm <- lm(mean ~ Task + Productive + Age, data = simple.model)
```

Next, we tested whether Productivity was significantly related to children's performance across the Unit, Next Number, and Math Facts tasks. We found that Productive counters had sigbnificantly greater mean performance for all three tasks in independent sample *t*-tests (all *p*s < .002) (Figure \ref{fig:3_tasks}). Further, this difference persisted for every number queried in each task (Figure \ref{fig:item}) (insert statistic here), indicating that Productive counters are more likely to have a generalized understanding of the successor function (Unit Task), recursion (Next Number Task), and addition with "+1" (Math Facts). 

While Productive counters exhibited higher performance across all three tasks, their performance on Math Facts was significantly lower than mean performance on the Unit and Next Number tasks. A linear regression predicting mean performance from task and controlling for the effects of Productivity and age revealed significant effects of task, with higher mean performance for both the Unit ($\beta$ = `r round(lm$coefficients[2], 2)`, $p < .0001$) and Next Number tasks ($\beta$ = `r round(lm$coefficients[3], 2)`, $p < .0001$). In addition to a main effect of Productivity ($\beta$ = `r round(lm$coefficients[4], 2)`, $p < .0001$), this model also revealed a significant effect of age ($\beta$ = `r round(lm$coefficients[5], 2)`, $p < .0001$).

Taken together, our analyses of children's performance across the Unit, Next Number, and Math Facts tasks indicate two things. First, our broad classification of Productivity captures a meaningful distinction not only in children's counting ability, but also in their general numerical knowledge, as evidenced by significantly greater performance for Productive counters across all three tasks. Second, children's proficiency with formally trained arithmetic operations seems to lag their conceptual understanding of these procedures, as shown by the significant decrease in performance on Math Facts in comparison to the Unit Task -- even for numbers that were repeated across both tasks. We will return to this difference in the discussion.

```{r item, fig.env = "figure*", fig.pos = "t", fig.width=7, fig.align = "center", set.cap.width = T, num.cols = 2, fig.cap = "Mean performance for Unit, Next Number, and Math Facts by item and Productivity"}
all.data %>%
  filter(Task == "MF" | 
         Task == "WCN" | 
           Task == "SF")%>%
  mutate(Task_item = factor(Task_item, levels = c("5", "6", "7", "15", "20", 
                                                  "21", "24", "26", "30", "32", 
                                                  "34", "46", "51", "57", "60", "62", "64", 
                                                  "71", "73", "81", "83", "84", "86",
                                                  "93", "95")), 
         Task = factor(Task, levels = c("SF", "WCN", "MF"), labels = c("Unit", 
                                                                       "Next Number", 
                                                                       "Math Facts")))%>%
  group_by(Productive, Task, Task_item)%>%
  summarise(mean = mean(Correct, na.rm = TRUE), 
            n = n(), 
            sd = sd(Correct, na.rm = TRUE), 
            se = sd/sqrt(n)) %>%
  ggplot(aes(x = Task_item, y = mean, colour = Productive, group = Productive)) +
  geom_point(size = 1) + 
  geom_line() +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
                width = .1) +
  theme_bw() + 
  facet_grid(~Task, scale = "free_x") +
  scale_colour_manual(values = productivity.pal) +
  theme(legend.position = "bottom", 
        legend.title = element_blank(), 
        axis.text = element_text(size = 6), 
        axis.title = element_text(size = 7), 
        strip.text.x = element_text(size = 6), 
        legend.text = element_text(size = 6), 
        strip.text = element_text(size = 8)) +
  labs(x = "Number queried", y = "Mean performance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  

#is this difference significant for every number? Figure out this analysis
```


##Predictors of successor knowledge

Our main question in this work was whether children acquired the successor function through mastery of recursion in the count list (Productive counting knowledge), or through trained arithmetic operations (Math Facts). To test these two hypothesized causal mechanisms, we constructed five individual logistics mixed effects models\footnote{All mixed effects models were fit in \texttt{R} using the \texttt{lme4} package. The model specification was: \texttt{Correct $\sim$ [Productivity/IHC/FHC/HCNN/mean Math Facts] + Within/Outside IHC + Age + ( 1 | subject)}. IHC, FHC, HCNN, and age were centered and scaled in order to fit the model.}, predicting accuracy on the Unit Task as a function of (1) Productivity; (2) Initial Highest Count; (3) Final Highest Count; (4) Highest Contiguous Next Number; and (5) mean Math Facts performance. 

In constructing our productivity models, we first tested whether Productivity, IHC, FHC, or HCNN individually predicted children's performance on the Unit Task. Likelihood ratio tests indicated that the addition of each term significantly improved the fit of the model, in comparison to the base (*p*s < .0001 for all tests). Because these productivity predictors may explain overlapping variance, we constructed our final productivity model hierarchically, using likelihood ratio tests to assess whether an individual predictor explained unique variance. This process of model comparison revealed HCNN and FHC as the best predictors of children's performance on the Unit Task (insert stat here). 

```{r}
model.df <- all.data %>%
  mutate(highest_contig = as.integer(highest_contig), 
         SID = factor(SID), 
         age.c = as.vector(scale(Age, center = TRUE, scale=TRUE)), #scale and center continuous variables for model fit
         fhc.c = as.vector(scale(FHC, center = TRUE, scale = TRUE)), 
         ihc.c = as.vector(scale(IHC, center = TRUE, scale = TRUE)),
         highest_contig.c = as.vector(scale(highest_contig, center = TRUE, scale=TRUE)), 
         highest_num.c = as.vector(scale(highest_num, center = TRUE, scale=TRUE)),
         mean.mf.c = as.vector(scale(mean.mf, center = TRUE, scale=TRUE)),
         starting_num.c = as.vector(scale(as.numeric(as.character(Task_item)), center = TRUE, scale = TRUE)))%>%
  filter(Task == "SF")
```

```{r}
#base
sf.base <- glmer(Correct ~ count_range  +age.c + (1|SID), 
                 family = "binomial", data = model.df)
#highest nn
sf.highest_nn <- glmer(Correct ~ highest_num.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#ihc
sf.ihc <- glmer(Correct ~ ihc.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#fhc
sf.fhc <- glmer(Correct ~ fhc.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Productive
sf.prod <- glmer(Correct ~ Productive + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Highest contiguous NN
sf.highest_contig <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)

#Productivity gradient
sf.prod.gradient <- glmer(Correct ~ prod.gradient + count_range + age.c + (1|SID), 
                 family = "binomial", data = model.df)
```

```{r}
#base v. highest nn
anova(sf.base, sf.highest_nn, test = 'LRT')
#base v. ihc
anova(sf.base, sf.ihc, test = 'LRT')
#base v. fhc
anova(sf.base, sf.fhc, test = 'LRT')
#base v. productive
anova(sf.base, sf.prod, test = 'LRT')
#base v. highest_contig
anova(sf.base, sf.highest_contig, test = 'LRT')
#base. v. prod. gradient
anova(sf.base, sf.prod.gradient, test = 'LRT')
```

```{r}
#HCNN
sf.large.base <- glmer(Correct ~ highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)

#FHC + HCNN 
sf.large.plusfhc <- glmer(Correct ~ fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.base, sf.large.plusfhc, test = 'LRT') #FHC adds to model

#IHC + FHC + HCNN 
sf.large.plusfhc.ihc <- glmer(Correct ~ ihc.c + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.base, sf.large.plusfhc, sf.large.plusfhc.ihc, test = 'LRT') #IHC does not add to model

##Productivity + FHC +  HCNN
sf.large.plusprod <- glmer(Correct ~ Productive + fhc.c + highest_contig.c + count_range + age.c + (1|SID), 
                       family = "binomial", data = model.df)
anova(sf.large.base, sf.large.plusfhc, sf.large.plusprod, test = 'LRT') #productivity does not add to this model 
```

```{r}
library(dotwhisker)
#visualizing regressions 
prod.model <- summary(sf.large.plusfhc)

data <- data_frame(a, b, c)

x <- data.frame(Parameter = as.character(), 
                Coefficient = as.numeric(), 
                `Std. Error` = as.numeric())
x$Parameter <- as.vector(prod.model$coefficient[,0])
x$Coefficient <- as.vector(prod.model$coefficient[,1]) 
x$`Std. Error` <- as.vector(prod.model$coefficient[,2])

ggplot(x, aes(x = Coefficient, y = Parameter, color = Parameter)) + 
  geom_point() + 
  geom_errorbar(aes(xmin = Coefficient - `Std. Error`, xmax = Coefficient + `Std. Error`), 
                width = .1) 
```

# Discussion

Third-level headings should be 10 point , initial caps, bold, and flush
left. Leave one line space above the heading, but no space after the
heading.

# Formalities, Footnotes, and Floats

Use standard APA citation format. Citations within the text should
include the author's last name and year. If the authors' names are
included in the sentence, place only the year in parentheses, as in
[-@NewellSimon1972a], but otherwise place the entire reference in
parentheses with the authors and year separated by a comma
[@NewellSimon1972a]. List multiple references alphabetically and
separate them by semicolons [@ChalnickBillman1988a; @NewellSimon1972a]. 
Use the et. al. construction only after listing all the authors to a
publication in an earlier reference and for citations with four or
more authors.

For more information on citations in RMarkdown, see **[here](http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html#citations).**

## Footnotes

Indicate footnotes with a number\footnote{Sample of the first
footnote.} in the text. Place the footnotes in 9 point type at the
bottom of the page on which they appear. Precede the footnote with a
horizontal rule.\footnote{Sample of the second footnote.} You can also use 
markdown formatting to include footnotes using this syntax [^1].

[^1]: Sample of a markdown footnote.

## Figures

All artwork must be very dark for purposes of reproduction and should
not be hand drawn. Number figures sequentially, placing the figure
number and caption, in 10 point, after the figure with one line space
above the caption and one line space below it. If necessary, leave extra white space at
the bottom of the page to avoid splitting the figure and figure
caption. You may float figures to the top or bottom of a column, or
set wide figures across both columns.

## Two-column images

You can read local images using png package for example and plot 
it like a regular plot using grid.raster from the grid package. 
With this method you have full control of the size of your image. **Note: Image must be in .png file format for the readPNG function to work.**

You might want to display a wide figure across both columns. To do this, you change the `fig.env` chunk option to `figure*`. To align the image in the center of the page, set `fig.align` option to `center`. To format the width of your caption text, you set the `num.cols.cap` option to `2`.

```{r 2-col-image, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "This image spans both columns. And the caption text is limited to 0.8 of the width of the document."}
img <- png::readPNG("figs/walrus.png")
grid::grid.raster(img)
```

## One-column images

Single column is the default option, but if you want set it explicitly, set `fig.env` to `figure`. Notice that the `num.cols` option for the caption width is set to `1`.

```{r image, fig.env = "figure", fig.pos = "H", fig.align='center', fig.width=2, fig.height=2, set.cap.width=T, num.cols.cap=1, fig.cap = "One column image."}
img <- png::readPNG("figs/lab_logo_stanford.png")
grid::grid.raster(img)
```


## R Plots

You can use R chunks directly to plot graphs. And you can use latex floats in the
fig.pos chunk option to have more control over the location of your plot on the page. For more information on latex placement specifiers see **[here](https://en.wikibooks.org/wiki/LaTeX/Floats,_Figures_and_Captions)**

```{r plot, fig.env="figure", fig.pos = "H", fig.align = "center", fig.width=2, fig.height=2, fig.cap = "R plot" }
x <- 0:100
y <- 2 * (x + rnorm(length(x), sd = 3) + 3)

ggplot2::ggplot(data = data.frame(x, y), 
       aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```


## Tables

Number tables consecutively; place the table number and title (in
10 point) above the table with one line space above the caption and
one line space below it, as in Table 1. You may float
tables to the top or bottom of a column, set wide tables across both
columns.

You can use the xtable function in the xtable package.

```{r xtable, results="asis"}
n <- 100
x <- rnorm(n)
y <- 2*x + rnorm(n)
out <- lm(y ~ x)

tab1 <- xtable::xtable(summary(out)$coef, digits=c(0, 2, 2, 1, 2), 
                      caption = "This table prints across one column.")

print(tab1, type="latex", comment = F, table.placement = "H")
```

# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
